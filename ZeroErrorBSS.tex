\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{mathtools,amssymb,amsfonts,amsthm,bm,dsfont}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{makecell}
% Bibliography Package
	\usepackage[numbers]{natbib}
% Custom Packages
	\usepackage{tikz}
	\tikzset{>=stealth}
% Custom Commands
	\newcommand{\rx}{\mathsf{x}}
	\newcommand{\ry}{\mathsf{y}}
	\newcommand{\rs}{\mathsf{s}}
	\newcommand{\rz}{\mathsf{z}}
	\newcommand{\ru}{\mathsf{u}}
	\newcommand{\rv}{\mathsf{v}}
	\newcommand{\rsh}{\hat{\mathsf{s}}}
	\newcommand{\rzs}{(\mathsf{z}_t)_{t\in\NN}}
	\newcommand{\rss}{(\mathsf{s}_t)_{t\in\NN}}
	\newcommand{\rus}{(\mathsf{u}_t)_{t\in\NN}}
	\newcommand{\rxs}{(\mathsf{x}_t)_{t\in\NN}} 
	\newcommand{\rys}{(\mathsf{y}_t)_{t\in\NN}}
	\newcommand{\rvs}{(\mathsf{v}_t)_{t\in\NN}} 
	\newcommand{\rshs}{(\hat{\mathsf{s}}_t)_{t\in\NN}}
	\newcommand{\part}{\hookrightarrow}
	\def\A{{\mathcal A}}
	\def\E{{\mathcal E}}
	\def\D{{\mathcal D}}
	\def\X{{\mathcal X}}
	\def\Y{{\mathcal Y}}
	\def\M{{\mathcal M}}
	\def\N{{\mathcal N}}
	\def\G{{\mathcal G}}
	\def\V{{\mathcal V}}
	\def\F{{\mathcal F}}
	\def\J{{\mathcal J}}
	\def\W{{\mathcal W}}
	\def\S{{\mathcal S}}
	\def\U{{\mathcal U}}
	\def\NN{{\mathbb N}}
	\def\QQ{{\mathbb Q}}
	\def\RR{{\mathbb R}}
	\newcommand{\RRc}{\RR_{\mathrm{c}}}
	\def\ZZ{{\mathbb Z}}
	\def\FF{{\mathbb F}}
	\def\CC{{\mathbb C}}
	\def\mM{\bm{\mathrm{M}}}
	\def\mA{\bm{\mathrm{A}}}
	\def\mC{\bm{\mathrm{C}}}
	\def\mB{\bm{\mathrm{B}}}
	\newcommand{\QE}{\mathcal{Q}_{\mathrm{E}}}
	\newcommand{\QD}{\mathcal{Q}_{\mathrm{D}}}
	\newcommand{\oQE}{\overline{\mathcal{Q}}_{\mathrm{E}}}
	\newcommand{\oQD}{\overline{\mathcal{Q}}_{\mathrm{D}}}
	\newcommand{\BSS}{\mathrm{BSS}}
	\newcommand{\TM}{\mathrm{TM}}
	\newcommand{\De}{\D_{\text{Est}}}
	\newcommand{\Dc}{\D_{\text{Ctrl}}}
	\newcommand{\cev}[1]{\reflectbox{\ensuremath{\vec{\reflectbox{\ensuremath{#1}}}}}}
	\newcommand{\RRcP}[1]{\mathrlap{\phantom{\RR}_{\mathrm{c}}}\RR^{#1}}
	\newcommand{\xp}[1]{\mathrlap{\phantom{x}^{\prime}}x_{#1}}
	\newcommand{\rp}[1]{\mathrlap{\phantom{r}^{\prime}}r_{#1}}
	\newcommand{\Wc}{\W_{\mathrm{c}}}
	\DeclareMathOperator{\Span}{Span}
% tikz-commands
	\newcommand{\wireless}{		\begin{tikzpicture}		\draw [domain=-45:45] plot ({cos(\x)}, {sin(\x)});
														\draw [domain=-45:45] plot ({1.5*cos(\x)}, {1.5*sin(\x)});
														\draw [domain=-45:45] plot ({2*cos(\x)}, {2*sin(\x)});
														\draw [domain=135:225] plot ({cos(\x)}, {sin(\x)});
														\draw [domain=135:225] plot ({1.5*cos(\x)}, {1.5*sin(\x)});
														\draw [domain=135:225] plot ({2*cos(\x)}, {2*sin(\x)});
								\end{tikzpicture}}
	\newcommand{\sender}{		\begin{tikzpicture}		\draw [domain=-45:45] plot ({cos(\x)}, {sin(\x)});
														\draw [domain=-45:45] plot ({1.5*cos(\x)}, {1.5*sin(\x)});
														\draw [domain=-45:45] plot ({2*cos(\x)}, {2*sin(\x)});
														\draw [domain=135:225] plot ({cos(\x)}, {sin(\x)});
														\draw [domain=135:225] plot ({1.5*cos(\x)}, {1.5*sin(\x)});
														\draw [domain=135:225] plot ({2*cos(\x)}, {2*sin(\x)});
														\draw[fill = black] (0,0) circle[radius = 0.5cm];
								\end{tikzpicture}}
	\newcommand{\receiver}{		\begin{tikzpicture}		\draw [domain=-45:45] plot ({cos(\x) -3}, {sin(\x)});
														\draw [domain=-45:45] plot ({1.5*cos(\x) -3}, {1.5*sin(\x)});
														\draw [domain=-45:45] plot ({2*cos(\x)-3}, {2*sin(\x)});
														\draw [domain=135:225] plot ({cos(\x) +3}, {sin(\x)});
														\draw [domain=135:225] plot ({1.5*cos(\x) +3}, {1.5*sin(\x)});
														\draw [domain=135:225] plot ({2*cos(\x) +3}, {2*sin(\x)});
														\draw[fill = black] (0,0) circle[radius = 0.5cm];
								\end{tikzpicture}}							
	\newcommand{\mobileagent}{	\begin{tikzpicture}		\draw (0,2.5) node[anchor = center] {\sender};
														\fill[color = black] (-0.15, 2.5) rectangle ( 0.15, -1);
														\fill[color = black!35] (0,-0.5) -- (1.5,-0.5) -- (2,-1) -- (5.5,-1) -- (6,-1.5) -- (5.5,-2) -- (3.5, -2) -- (3,-2.5) -- (1.5,-2.5) -- (1,-3) --%
																				(-1,-3) -- (-1.5,-2.5) -- (-3,-2.5) -- (-3.5, -2) -- (-5.5,-2) -- (-6,-1.5) -- (-5.5,-1) -- (-2,-1) -- (-1.5,-0.5) --cycle;
														\fill[color = black]	(1.5,-2.5) -- (2.5, -3.5) -- (2.5, -5.5) -- (3.5, -5.5) -- (3.5, -3.5) -- (2.5, -2.5) -- cycle;
														\fill[color = black]	(-1.5,-2.5) -- (-2.5, -3.5) -- (-2.5, -5.5) -- (-3.5, -5.5) -- (-3.5, -3.5) -- (-2.5, -2.5) -- cycle;
														\fill[color = black!35] (4,-1) -- (4.5,-0.5) -- (4.5, 0.5) -- (4.75,1) -- (5,0.5) -- (5,-0.5) -- (5.5, -1) -- cycle;
														\fill[color = black] (1,0.25) -- (1.25, 0.5) -- (8.25, 0.5) -- (8.5, 0.25) -- (8.25, 0) -- (1.25, 0) -- cycle;
														\fill[color = black!35] (-4,-1) -- (-4.5,-0.5) -- (-4.5, 0.5) -- (-4.75,1) -- (-5,0.5) -- (-5,-0.5) -- (-5.5, -1) -- cycle;
														\fill[color = black] (-1,0.25) -- (-1.25, 0.5) -- (-8.25, 0.5) -- (-8.5, 0.25) -- (-8.25, 0) -- (-1.25, 0) -- cycle;
														%\draw[very thick, color = black] (-0.3,0.1) circle[radius = 1.25mm];
														%\draw[very thick, color = black] (0.3,0.1) circle[radius = 1.25mm];
														%\draw[color = black] (-1,-0.1) -- (1,-0.1);
														%%\fill[color = white] (-0.4,0.075) circle[radius = 1mm];
														%%\fill[color = white] (0.4,0.075) circle[radius = 1mm];
														%\fill[very thick, fill = black!35] 	(-0.6, 0.3) -- (-0.2, 0.3) -- (0, 0.2) -- (0.2,0.3) --  (0.6, 0.3) --%
																								%%(-0.3,0.1) -- (0.3,0.1) -- cycle; %<= Motorcycle 
																								%(0.3,0.1) -- (-0.3,0.1) -- cycle;
														%\draw[thick, color = black!35] (0,0.15) -- (0,0.6);
														%\fill[color = black] (0,0.6) circle[radius = 0.75mm];
														%\draw (0,0.6) node[scale = 0.15] {\wireless};
														%%\draw[very thick, color = black!35] (0.2,0.3) -- (0.3,0.1);
														%%\draw[very thick, color = black!35] (-0.2,0.3) -- (-0.3,0.1);
								\end{tikzpicture}}
	\newcommand{\basestation}{	\begin{tikzpicture} 	\draw[thick, color = black] (0,0.1) -- (0,0.6);
														\fill[color = black] (0,0.6) circle[radius = 0.75mm];
														%\draw[color = black] (-0.6,-0.1) -- (0.6,-0.1);
														\draw (0,0.6) node[scale = 0.15] {\wireless};
														\fill[color = black!35] (-0.2, 0.2) -- (0, 0) -- (0.2,0.2) -- cycle;
								\end{tikzpicture}}
	\newcommand{\bigarrow}{		\begin{tikzpicture}		\shade[ultra thick, right color = black!10, left color = black!35] (-0.3,-2.2) -- (-1.7,-2.2) -- (-2.2,-1.5) -- (-1.7, -0.8) -- (-0.3,-0.8);
								\end{tikzpicture}}
	\newcommand{\initstate}{	\begin{tikzpicture}		\draw[very thick, ->, shorten >=1.5pt] (-4.5,1.75) -- (-2,1.75); 
														\draw (-3.25,1.75)  node[fill = white, anchor=center, align=center]
														{\(\rs_0\)};
														\draw (-4.5,1.75)  node[fill = white, anchor=center, align=center]
														{\(\dots\)};
								\end{tikzpicture}}
	\newcommand{\plantdist}{	\begin{tikzpicture}		\draw[very thick, ->, shorten >=1.5pt] (-4.5,1.25) -- (-2,1.25); 
														\draw (-3.25,1.25)  node[fill = white, anchor=center, align=center]
														{\(\rzs\)};
														\draw (-4.5,1.25)  node[fill = white, anchor=center, align=center]
														{\(\dots\)};
								\end{tikzpicture}}
	\newcommand{\plant}{		\begin{tikzpicture}		\draw[thick, fill=black!35] (0,0) rectangle (2,1);
														\draw (1,0.5)  node[anchor=center] {\(\mA\)};
														\draw (1,1)  node[anchor=south] {Plant};
														\draw[thick, ->, shorten >= 0.5mm] (2,0.5) -- (4,0.5);
														\draw (3,0.5) node[anchor = south] {\(\rss\)};
								\end{tikzpicture}}
	\newcommand{\planttosens}{	\begin{tikzpicture}		\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (0,1.5) -- (2.5,1.5); 
														\draw (1.25,1.5)  node[fill = white, anchor=center]
														{\(\rss\)};
								\end{tikzpicture}}
	\newcommand{\sens}{			\begin{tikzpicture}		\draw[thick, fill=black!35] (4.5,2) rectangle (2.5,1);
														\draw (3.5,1.5)  node[anchor=center] {\(\mB\)};
														\draw (3.5,2)  node[anchor=south] {Sensor};
								\end{tikzpicture}}
	\newcommand{\senstoenc}{	\begin{tikzpicture}		\draw[very thick, <-, shorten >=1.5pt, shorten <=1.5pt] (4,-1) -- (4,1); 
														\draw (4,0)  node[fill = white, anchor=center, align=center]
														{\(\rus\)};
								\end{tikzpicture}}
	\newcommand{\enc}{			\begin{tikzpicture}		\draw[thick, fill=black!35] (4.5,-2) rectangle (2.5,-1);
														\draw (3.5,-1.5)  node[anchor=center] {\(\E\)};
														\draw (3.5,-1)  node[anchor=south] {Encoder};
								\end{tikzpicture}}
	\newcommand{\enctochan}{	\begin{tikzpicture}		\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (2.5,-1.5) -- (-0.3,-1.5); 
														\draw (1.25,-1.5)  node[fill = white, anchor=center, align=center]
														{\(\rxs\)};
								\end{tikzpicture}}
	\newcommand{\chan}{			\begin{tikzpicture}		\draw[thick, fill = black!25] (-2,-1.5) -- (-1.7, -1.1) -- (0,-1.1) -- (-0.3,-1.5) -- (0,-1.9) -- (-1.7,-1.9) -- (-2,-1.5);
														\draw (-1,-1.5)  node[anchor=center] {\(W\)};
														\draw (-1,-2)  node[anchor=north] {DMC};
								\end{tikzpicture}}
	\newcommand{\chantodec}{	\begin{tikzpicture}		\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (-2,-1.5) -- (-4.5,-1.5); 
														\draw (-3.25,-1.5)  node[fill = white, anchor=center, align=center]
														{\(\rys\)};
								\end{tikzpicture}}
	\newcommand{\dec}{			\begin{tikzpicture}		\fill[fill=black!15, rounded corners=0.1cm] (-6.5,-2) rectangle (-4.5,-1);
														\draw (-5.5,-1.5)  node[anchor=center] {\(\De\)/\(\Dc\)};
														\draw (-5.5,-2)  node[anchor=north] {Estimator/Controller};
								\end{tikzpicture}}
	\newcommand{\stateestim}{	\begin{tikzpicture}		\draw[very thick, ->, shorten <=1.5pt] (-6,-1) -- (-6,1);
														\draw (-6,0)  node[fill = white, anchor=center, align=center]
														{\(\rshs\)};
														\draw (-6,1.5)  node[fill = white, anchor=center, align=center]
														{\(\vdots\)};
								\end{tikzpicture}}
	\newcommand{\controllink}{	\begin{tikzpicture}		\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (-5,-1) -- (-5,-0.5) -- (-1.5,0.5) -- (-1.5,1);
														\draw (-3.25,0)  node[fill = white, anchor=center, align=center]
														{\(\rvs\)};
								\end{tikzpicture}}
% Editing
	\newcommand{\rdummy}{{\color{red}[REF]}}
	\newcommand{\sdummy}{{\color{red}[SOURCE]}}
	\newcommand{\edited}{\color{black}}
	\newenvironment{RV}	{	\noindent\color{red}\textbf{Revision.}~\textit
						}{ 	\hfill\mbox{}\par
						}
	%\newcommand{\revision}[1]{\begin{RV}#1\end{RV}}
	\newcommand{\revision}[1]{}
% Custom Environments
	\newtheorem{Theorem}{Theorem}
	\newtheorem{Definition}[Theorem]{Definition}
	\newtheorem{Lemma}[Theorem]{Lemma}
	\newtheorem{Corollary}[Theorem]{Corollary}
	\newtheorem{Remark}[Theorem]{Remark}
%	%	%	%	%	
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
%
	\title{Decision-Making for Network-Controlled Systems:\\ Decidability on Digital and Real Number\\ Information Processing Hardware
		%\thanks{H.~Boche was supported by the German Research Foundation (DFG) within
				%the Gottfried Wilhelm Leibniz Prize under Grant BO 1734/20-1, within
				%Germany’s Excellence Strategy EXC-2111—390814868 and EXC-2092 CASA -
				%390781972
				%and by the German Federal Ministry of Education and Research (BMBF)
				%within the national initiative for “Post Shannon Communication (NewCom)”
				%with the
				%project “Basics, simulation and demonstration for new communication
				%models” under Grant 16KIS1003K.
				%C.~Deppe was supported by the BMBF within NewCom with the project
				%“Coding theory and coding methods for new communication models” under
				%Grant 16KIS1005, by the German Research Foundation (DFG)
				%with the Project "Post-Shannon theory and implementation" under Grant DE
				%1915/2-1 and by the German Federal Ministry of Education and Research
				%(BMBF) within the project "6G-life" under Grant 16KISK002.}
	}
	\author{\IEEEauthorblockN{Holger Boche}
	\IEEEauthorblockA{\textit{Institute for}\\ 
	\textit{Theoretical Information Technology,}\\
	\textit{Technical University of Munich}\\
	Munich, Germany\\
	boche@tum.de\\
	ORCID: 0000-0002-8375-8946}
	\and
	\IEEEauthorblockN{Yannik Böck}
	\IEEEauthorblockA{\textit{Institute for}\\ 
	\textit{Theoretical Information Technology,}\\
	\textit{Technical University of Munich}\\
	Munich, Germany \\
	yannik.boeck@tum.de\\
	ORCID: 0000-0001-7640-6988}
	\and
	\IEEEauthorblockN{Christian Deppe}
	\IEEEauthorblockA{\textit{Institute for}\\
	\textit{Communications Engineering,}\\
	\textit{Technical University of Munich}\\
	Munich, Germany \\
	christian.deppe@tum.de\\
	ORCID: 0000-0002-2265-4887}
	}

\maketitle

\begin{abstract}
	We consider a decision problem associated to the task of remotely estimating and stabilizing the state of an unstable, 
	linear time-invariant plant via a discrete, memoryless channel: given the channel's characteristics, does there exist a pair 
	of encoder and estimator/controller that allows for the estimation and stabilization the plant's state? 
	Analytically, this problem has been shown to involve the zero-error and feedback zero-error capacity of the channel. 
	Starting from this result, we approach the problem from an algorithmic point of view. 
	In particular, we investigate whether there exist Turing and/or Blum-Shubs-Male machines that solve the decision problem
	based on a machine-readable description of the channel. Questions of this kind are becoming increasingly important in information technology.
	Future cyber-physical networks are expected to incorporate distributed control and decision making to a large extend,
	while simultaneously adapting to changes in evironmental conditios in an autonomous manner. 
	On the one hand, the potential of digital technology is fully characterized by the theory of Turing machines.
	On the other hand, the Blum-Shubs-Male machine model is commonly employed in numerics and enigeering, usually in an implicite manner. 
	In providing an applied comparison of the different implications of both machine models real-world technologies,
	we aim to contribute to the understanding of fundamental limits and possible pitfalls of cyber-physical technologies.
	In the broadest sense, our findings relate to the question of which machine models adequately represent the capabilities of 
	different hardware platforms. 
\end{abstract}

\begin{IEEEkeywords}
	\textcolor{red}{Co-Design of Communications and Control, Remote State Estimation, Noisy Channels, Neuromorphic Computing.} 
\end{IEEEkeywords}

\section{Introduction}	\label{sec:Introduction}
	\IEEEPARstart{R}{emote} and/or distributed decision making is becoming increasingly important in view of future communication networks. The ideas behin well known topics like 
	``Industry 4.0'', ``Autonomous Driving'', ``Internet of Things'' and ``Metaverse'' are examples for the currentd trend in communications to shift the focus away from pure data transmission 
	towards interconnected information processing in a virtual space and control of agents that interact with the physical world. Networks of this kind, i.e., those that contain both 
	virtual and physical components, belong to a class of technologies that are commonly referred to as \emph{cyber-physical systems} \cite{AlEl17, BaCaFo19, Do21}.
	\revision{``Slogans'' was changed to ``topics''.}
	
	In many cases, cyber-physical networks are a field of application for control engineering, since, per definition, they contain physical components that act within the real world. 
	However, as compared to classical control engineering, cyber-physical physical networks aim to solve control problems remotely in a distributed and cooperative fashion, 
	ranther than individually and locally at every physical component. Remote state estimation and sabilization via noisy communication channels, which is a prominent problem 
	in control theory \cite{MS07, MS07SC}, is thus naturally a part of many cyber-physical systems, either in an implicite or explicite manner. 
	From a theoretical point of view, the problem can informally be described as follows. The state of an unstable linear time-invariant \emph{(LTI)} plant is observed by a local sensor. 
	Subsequently, the sensor data is feed into an encoder that prepares the data for transmission trough a discrete, memoryless channel \emph{(DMC)}. 
	At the receiving end, the sequence of channel outputs is processed by a remote estimator/controller. The latter tries to estimate and/or stabilize the state of the plant, where 
	the stabilization task requires the possibility of affecting the plant's state by means of a feedback link. The setup is schematically depicted in Figure \ref{fig:Schematics}.
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}[every node/.style={scale=0.7}]
				\begin{scope}[shift = {(0,2)}]	\fill[fill=black!10, rounded corners=0.05cm] (-4.5,0.4) rectangle (3.5,-1.3);
												\draw[thick, fill = black!35] (-3.25,0) rectangle (-1.75,-0.75);
												\draw[very thick, ->, shorten >= 0.5mm] (-1.75,-0.375) -- (-0.75,-0.375);
												\draw[very thick, ->, shorten >= 0.5mm] (0.75,-0.375) -- (1.75,-0.375);
												\draw[very thick, ->, shorten >= 0.5mm] (-4.25,-0.25) -- (-3.25,-0.25);
												\draw[very thick, ->, shorten >= 0.5mm] (-4.25,-0.5) -- (-3.25,-0.5);
												\draw (-4.5,-0.25) node[anchor = center] {\(\cdots\)};
												\draw (-4.5,-0.5) node[anchor = center] {\(\cdots\)};
												\draw (-1.25,-0.375) node[anchor= south] {\(\rss\)};
												\draw (1.25,-0.375) node[anchor= south] {\(\rus\)};
												\draw (-3.75,-0.5) node[anchor= north] {\(\rs_0\)};
												\draw (-3.75,-0.25) node[anchor= south] {\(\rzs\)};
												\draw[thick, fill = black!35] (-0.75,0) rectangle (0.75,-0.75);
												\draw[thick, fill = black!35] (1.75,0) rectangle (3.25,-0.75);
												\draw (-2.5,-0.375) node[] {\(\mA\)};
												\draw (0,-0.373) node[] {\(\mB\)};
												\draw (2.5,-0.375) node[] {\(\E\)};
												\draw (-2.5,0) node[anchor = south] {Plant};
												\draw (0,0) node[anchor = south] {Sensor};
												\draw (2.5,0) node[anchor = south] {Encoder};
												\draw (-4.5,-1.3) node[anchor = south west] {Mobile Agent};
				\end{scope}
				\fill[color = black!10, rounded corners=0.05cm] (1, 0.55) rectangle (3,-0.55);
				\fill[color = black!10, rounded corners=0.05cm] (-1, 0.55) rectangle (-3,-0.55);
				\begin{scope}[shift = {(0,-2)}]	\fill[fill=black!10, rounded corners=0.05cm] (-4.5,-0.4) rectangle (3.5,1.3);
												\draw[thick, fill = black!35] (-3.25,0) rectangle (3.25,0.75);
												\draw[very thick, <-] (-4.25,0.375) -- (-3.25,0.375);
												\draw (-4.5,0.375) node[anchor = center] {\(\cdots\)};		
												\draw (-3.75,0.375) node[anchor= north] {\(\rshs\)};
												\draw (0,0.375) node[] {\(\Dc\)~/~\(\De\)};
												\draw (0,0) node[anchor = north] {Controller/Estimator};
												\draw (-4.5,1.3) node[anchor = north west] {Base Station};
				\end{scope}
				\draw (2.5, 0.925) node[anchor = east] {\(\rxs\)};
				\draw (2.5, -0.925) node[anchor = east] {\(\rys\)};
				\draw (-2.5, -0.925) node[anchor = west] {\(\rvs\)};
				\draw (-2.5, 0.925) node[anchor = west] {\(\rvs\)};
				\draw[very thick, ->, shorten >= 0.5mm] (2.5, 1.25) -- (2.5, 0.3);
				\draw[very thick, <-, shorten <= 0.5mm] (2.5, -1.25) -- (2.5, -0.3);
				\draw[very thick, <-, shorten <= 0.5mm] (-2.5, 1.25) -- (-2.5, -1.25);
				\draw (1, 0) node[anchor = west, align = left] {Noisy \\ Channel};
				\draw (-1, 0) node[anchor = east, align = right] {(Noiseless) \\ Feedback \\ Link};
				\draw (2.5, 0.3) node[anchor = center, scale = 0.15] {\sender};
				\draw (2.5, -0.3) node[anchor = center, scale = 0.15] {\receiver};
				\draw (2.5, 0) node[anchor = center] {\(W\)};
		\end{tikzpicture}
		\caption{Schematics of the remote state estimation and stabilization setup considered throughout this article.}
		\label{fig:Schematics}
	\end{figure}    
	
	The expectations towards future cyber-physical networks are manifold. In classical control engineering,
	the controller of a time invariant, dynamic system is designed by an engineer during the process of the system's developement, with respect to the system's indicidual characteristics.
	Cyber-physical networks, on the other hand, are often required to adapt to changing environmental conditions at runtime, while simultaneously operating in a fully autonomous manner.
	In the context of remote state estimation and stabilization, changing environmental conditions correspond to time variant characteristics of the transmission channel.
	Hence, the autonomous operation of a remote state estimation and stabilization system includes channel estimation and the automated generation of a suitable pair of encoder and estimator/controller
	for each transmission frame. In a more general scope, \emph{digital twins} are regularly mentioned as the future key technology for implementing autonomous cyber-physical systems 
	\cite{RaSaKv20,TaZhLiNe19,BaCaFo19,QiTa18,AlEl17}. The approach is based on creating virtual copies of the system's physical agents, which are then employed for optimization, control tasks and 
	decision-making. Examples of cyber-physical and digital twin technologies that implicitely include remote state estimation and stabilization 
	can be found e.g. in \cite{GuSiKuNi18, LiNgLeSoSt16}, or in \cite{Kr16}, the latter being a patent held by the \emph{Siemens AG Munich}. For cyber-physical networks, the method can 
	be extended as far as to implement a virtual copy of the full network itself, which may then be used e.g. for the generation of channel-coding schemes at runtime. The concept is
	visualized in Figure \ref{fig:DigitalTwin}.
	\revision{Are all of these references \cite{RaSaKv20,TaZhLiNe19,BaCaFo19,QiTa18,AlEl17} necessary? Maybe reduce to three.}
	\revision{In the above paragraph, ``cyber-physical, digital twin'' was changed to ``cyber-physical and digital twin'' in order to match the sources. Review consistency of paragraph
	(and introduction as a whole) in view of this.}
	\begin{figure}[h]\linespread{1}
		\centering
		\begin{tikzpicture}[scale = 1, every node/.style={scale=1}]
			\begin{scope}[shift={(0,2.2)}]	\fill[fill=black!10, rounded corners=0.05cm] (-4,2) rectangle (4,-2);
											\draw (4,-2) node[anchor = south east, scale = 0.7] {Physical Network};
											\draw (-3,-1) node[anchor = center] {\basestation};
											\draw (3,1) node[anchor = center] {\basestation};
											\draw (-2,0.8) node[anchor = center, scale = 0.1] {\mobileagent};
											\draw (0,0) node[anchor = center, scale = 0.1] {\mobileagent};
											\draw (2,-0.8) node[anchor = center, scale = 0.1] {\mobileagent};
			\end{scope}
			\begin{scope}[shift={(0,-2.2)}]	\fill[fill=black!10, rounded corners=0.05cm] (-4,2) rectangle (4,-2);
											\draw (4,2) node[anchor = north east, scale = 0.7] {Digital Twin};
											\draw (-3,-1) node[draw, anchor = center] {\(\mathtt{BASE}~1\)};
											\draw (3,1) node[draw, anchor = center] {\(\mathtt{BASE}~2\)};
											\draw (-2,0.8) node[draw, anchor = center] {\(\mathtt{MOBILE}~1\)};
											\draw (0,0) node[draw, anchor = center] {\(\mathtt{MOBILE}~2\)};
											\draw (2,-0.8) node[draw, anchor = center] {\(\mathtt{MOBILE}~3\)};
											\draw[very thick, shorten >= 0mm, shorten <= 0mm, <->] (-1.1,0.8) -- (0,0.35);
											\draw[very thick, shorten >= 4mm, shorten <= 4mm, <->] (-3,-1) -- (-2,0.8);
											\draw[very thick, shorten >= 7.5mm, shorten <= 9mm, <->] (0,0) -- (-3,-1);
											\draw[very thick, shorten >= 0mm, shorten <= 0mm, <->] (1.1,-0.8) -- (0,-0.35);
											\draw[very thick, shorten >= 4mm, shorten <= 4mm, <->] (3,1) -- (2,-0.8);
											\draw[very thick, shorten >= 7.5mm, shorten <= 9mm, <->] (0,0) -- (3,1);
			\end{scope}
			\draw (-1.5,0.28) node[rotate = 90, scale = 0.5, anchor = east]{\bigarrow};
			\draw (0,-0.28) node[rotate = 270, scale = 0.5, anchor = east]{\bigarrow};
			\draw (-1.5,0.2) node[anchor = south, align = center, scale = 0.7]{Measurements, \\ Sensor Data};
			\draw (0,-0.2) node[anchor = north, align = center, scale = 0.7]{Decision-Making, \\ Control};
		\end{tikzpicture}
		\caption{Visualization of the interaction between a physical network and its virtual, digital twin.}
		\label{fig:DigitalTwin}
	\end{figure}   
	
	Future cyber-physical networks are expected to be applied in security- and safety-critical systems to a great extent, as is the case in e.g. autonomous driving.
	Hence, strict requirements regarding technology assessment and verification are necessary. In particular, this concerns questions of trustwortiness, integrity, 
	fault-detection and -tolerance and, in the broadest sense, machine ethics. The significane of these considerations is reflected in the ongoing discussions within the scientific community 
	\cite{RaSaKv20, AwDsKiScHeShBoRa18, ShHeZh16, FeBo21, FeBo22, BoScPo21, GePoBeLuLi21}. 
	In order to obtain a qualified evaluation of whether some cyber-physical system meets the abovementioned requirements, it is necessary to precisely understand 
	the fundamental boundaries of digital technology from a theoretical point of view. In fact, some of the trustworthiness and integrity requirements discussed in the context of 5G and 6G mobile
	communication networks have already been shown to exceed the theoretical limitations of digital systems \cite{FeBo21, FeBo22, BoScPo21, BoBoDe21TAC}. Never the less, current research in the field 
	of cyber-physical systems and digital twins does not seem to provide many attemts towards modeling cyber-physical systems in a fundamental and mathematically consistent manner. 
	As is hinted in \cite{TaZhLiNe19}, universal theoretical frameworks that provide a sound fromalization of cyber-physicality and digital twinning are critically underdeveloped.
	\revision{The ``ongoing discussions within the scientific community'' mentioned above is not limited to one specific nieche of engineering but instead spans a broad range of
	scientific fields.} 
	
	This work aims to provide a contribution towards the understanding of fundamental limits and possible pitfalls of cyber-physical technologies from a theoretical point of view.
	To this end, we apply the theory of Turing and Blum-Shub-Smale machines to the problem of remote state estimation and stabilization in terms of a decidability analysis. That is,
	we investigate whether there exist algorithms on Turing and Blum-Shub-Smale machines that decide whether it is possible to remotely estimate and/or stabilize the state of an unstable LTI plant
	based on a description of the communication channel. Any autonomous system handling remote state estimation and stabilization scenarios involves this decision problem, 
	either in an explicite manner, or implicitely when computing a suitable pair of encoder and estimator/controller.
	In essence, this task reduces to a channel classification problem. The latter occur frequently in different variants throughout network theory \cite{BoScPo21}.   
	
	The theory of Turing machines yields a precise indication of the fundamental capabilities of real-world, digital hardware. Any problem that cannot be solven in theory on a Turing machine
	can certainly not be solved on a real-world (digital) computer. Never the less, it is common in numerics and engineering to employ Blum-Shub-Smale machines,
	which give rise to a formal framework for the algorithmic processing of real numbers, as the underlying machine model. Usually, this is done for reasons of convenience and in an implicite manner. 
	By investigating the abovementioned decision problem for both Turing and Blum-Shub-Smale machines, we want to provide an applied comparison of the different implications of 
	both models for real-world technologies. 
	
	The outline of the remainder of our work is as follows. In Section \ref{sec:FormalEstimationSetup}, we provid a formal description of the remote state estimation and stabilization problem
	and discuss the preliminaries that lead to the associated channel classficaton problem. In Section \ref{sec:introTuring}, we introduce the fundamentals of Turing theory.
	Based on the latter, we estabish two general results on channel classification problems, one of which exhibits a notable interpretation in the context of system verification. 
	In Section \ref{sec:PreliminariesBSS}, we introduce the fundamentals of Blum-Shub-Smale theory. Furthermore, we prove the existence of 
	Blum-Shub-Smale agorithms that compute the zero-error and feedback zero-error capacity of discrete, memoryless channels on fixed pairs of channel input and channel output alphabet. 
	In Section \ref{sec:DecidingRemoteStateEstimationOnBSS}, we investigate the decidability of the remote state estimation and sabilization problem 
	by applying the results we estabished in Sections \ref{sec:introTuring} and \ref{sec:PreliminariesBSS}. Section \ref{sec:Conclusion} concludes the paper with some additional 
	remarks on the implications of our findings. 
                                                                        
%\color{gray}
\section{Formal Description of the Remote State Estimation and Stabilization Setup}	\label{sec:FormalEstimationSetup}
	
	\subsection{Formal Setup Description}
	\noindent In to following, we give a formal description of the setup depicted in Figure \ref{fig:Schematics}, as well as a brief summary of 
	some relevant results concerning different variants of the related estimation and control problem. Originally, these were derived in \cite{MS07, MS07SC}.  
	
	As indicated in Section \ref{sec:Introduction}, 
	the remote state estimation and stabilization problem revolves around the state sequence \((\rs_t)_{t\in\NN}\) 
	of an unstable LTI system. The system's dynamics are modelled by means of a matrix \(\mA \in \RR^{n\times n}\), which governs the evolution of \((\rs_t)_{t\in\NN}\) 
	according to the set of equations 
	\begin{align*}	 \rs_{t+1}    	= \mA \rs_t + \rz_t + \rv_t, 
	\end{align*}
	Here, the sequence \((\rz_t)_{t\in\NN}\) accounts for noise-like disturbances in the system's state progression and the sequence \(\rvs\) incorporates a control input. 
	Furthermore, the inital state \(\rs_0\) is assumend to emerge randomly according to some probability measure. 
	The system status is continuously monitored by a local sensor, which is characterized by a matrix \(\mB\in\RR^{n\times m}\). The sensor relates the
	state sequence \((\rs_t)_{t\in\NN}\) to a sequence \(\rus\) of measurements, conforming to the set of equations
	\begin{align*}	\ru_t    = \mB \rs_t.
	\end{align*}  	
	Based on the avaiable sensor data, an encoder succesively chooses channel inputs from a finte alphabet \(\X\). Mathematically, this is captured by the relation
	\begin{align*}	\rx_t   = \E \big(t, (\ru_{t'})_{t'=1}^{t}\big) 							= \E\big(t, \ru_1,\ru_2,\ldots,\ru_t\big).
	\end{align*}
	The sequence of channel outputs \((\ry_t)_{t\in\NN}\) is a sequence
	of symbols from another finite alphabet \(\Y\), and is related component-wise to the sequence \((\rx_t)_{t\in\NN}\) by a conditional probability mass function
	\begin{align*}	W :~ \Y \times \X \rightarrow \RR_{\hspace{1pt}0}^+,~(y,x) \mapsto W(y|x).
	\end{align*}
	The triple \((\X,\Y,W)\) fully characterizes the behaviour of the communication unit, and is referred to as a \emph{discrete, memoryless channel} (DMC).
	Last but not least, at the receiving end, the plant's state sequence is estimated according to a relation
	\begin{align*}	\hat{\rs}_t  	&= \De\big(t, (\ry_{t'})_{t'=1}^{t}\big)  \\
									&= \De\big(t,\ry_1,\ry_2,\ldots,\ry_t\big).
	\end{align*}
	Depending on the specific objective, a control input 
	\begin{align*}	\rv_t  			&= \Dc\big(t, (\ry_{t'})_{t'=1}^{t}\big)  \\
									&= \Dc\big(t,\ry_1,\ry_2,\ldots,\ry_t\big)
	\end{align*}
	is generated, which is then fed back to the dynamic system via a control-loop. Otherwise, if the objective concerns the estimation
	of the state sequence, we set
	\begin{align}	\label{eq:No_Ctrl_Loop}
					\Dc\big(t,\ry_1,\ry_2,\ldots,\ry_t\big) = \bm{0}
	\end{align}
	for all \(t\in\NN\), where \(\bm{0}\) denotes the \emph{zero-vector} in \(\RR^{n}\). 
	 
	In general, the task is to design suitable pair of encoder and estimation- and control-unit. The question of which pairs are deemed \emph{suitable} 
	depends first and foremoste on the specific objective regarding estimation and control, the behavior of the dynamic system as characterized by the matrix \(\mA\), 
	and the quantitative ability of the communication channel to transmit inforamtion. The latter is is expressed in terms of \emph{channel capacities}, the 
	relevant of which are the \emph{Shannon capacity} \cite{Sh48}, the \emph{zero-error capacity} \cite{Sh56} and the \emph{feedback zero-error capacity} \cite{Sh56}, 
	\begin{align*} C, C_{0}, C_{\text{Fb}}:~ \W(\X,\Y) \rightarrow \RR_{\hspace{1pt}}^{+},
	\end{align*}
	where \(\W(\X,\Y)\) is the set of conditional probability mass functions on finite alphabets \(\X\) and \(\Y\),
	\begin{align*}	\W(\X,\Y)	:=	\bigg\{ W: 	&~\X \times \Y \rightarrow\RR_{\hspace{1pt}0}^+,~ (x,y) \mapsto W(y|x),\\
												&~\forall x\in\X: ~{\sum}_{y\in\Y} W(y|x) = 1 \bigg\}.
	\end{align*}
	For a comprehensive introduction to different measures of information and their properties, we refer to \cite{CsKo11}.  
	As we will explain in the course of this section, the objective regarding estimation and control fully determines 
	which capacity has to be employed as a quantification of channel quality.
	
	The amount of data that needs to be transmitted depends exclusively on the characteristics of the dynamic system. 
	For \(\mA \in \RR^{n\times n}\), denote \(\bm{\lambda}(\mA) := (\lambda_1(A),\lambda_2(A),\ldots,\lambda_n(\mA))\) a family 
	consisting of all eigenvalues of \(\mA\), according to their algebraic multiplicity. Consequently, the family \(\bm{\lambda}(\mA)\)
	consists of exactly \(n\) components for all \(\mA\in \RR^{n\times n}\). We define
	\begin{align}	\eta(\mA):={\sum}_{j:|\lambda_j(\mA)|\geq 1} \log_2|\lambda_j(\mA)|.
	\end{align}
	Informally, the quantity \(\eta(\mA)\) equals the average number of bits that need to be transmitted per time instance in order
	to sucessfully estimate and control the state sequence \(\rss\).
	
	It remains to provide a formal objective regarding the estimation and control of the system's state sequence. The following variants were considered
	in \cite{MS07, MS07SC}. Each has been shown to involve one of the abovementioned capacities.
	
	1 - \(C_{\text{Sh}}\): \emph{State Estimation for Undisturbed Plants.} The scenario is characterized by the assumtion of a fully deterministic 
	state evolution, aside from the initial state being choosen at random. In other words, the sequence of noise-like fluctuations affecting the system satisfies
	\(\rz_t = \bm{0}\) for all \(t\in\NN\). The task is to design a pair \((\E,\De)\)
	(with \(\Dc\) satisfying \eqref{eq:No_Ctrl_Loop}) such that \(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| = 0\) holds true with probability \(p > \delta\).
	If \(\eta(\mA) < C_{\text{Sh}}\) is satisfied, there exists, for all \(0 \leq \delta < 1\), a pair \((\E,\De)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{\text{Sh}}\) is satisfied, there exists \(0 < \delta \leq 1\) such that for all possible pairs \((\E,\De)\), we have 
	\(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| = \infty\) with probability \(p > \delta\).	
		
	2 - \(C_{\text{Sh}}\): \emph{Stabilization for Undisturbed Plants.} The scenario is analogous to state estimation for undisturbed plants. 
	The task is to design a pair \((\E,\Dc)\) such that \(\limsup_{t\in\NN} \|\rs_t\| = 0\) holds true with probability \(p > \delta\).
	If \(\eta(\mA) < C_{\text{Sh}}\) is satisfied, there exists, for all \(0 \leq \delta < 1\), a pair \((\E,\Dc)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{\text{Sh}}\) is satisfied, there exists \(0 < \delta \leq 1\) such that for all possible pairs \((\E,\Dc)\), we have 
	\(\limsup_{t\in\NN} \|\rs_t\| = \infty\) with probability \(p > \delta\).
	
	3 - \(C_{0}\): \emph{State Estimation for Disturbed Plants.} The task is to design a pair \((\E,\De)\)
	(with \(\Dc\) satisfying \eqref{eq:No_Ctrl_Loop}) such that \(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| < \infty\) holds true almost surely.
	The the sequence of noise-like fluctuations may be bounded arbitrarily close to zero.
	If \(\eta(\mA) < C_{0}\) is satisfied, there exists a pair \((\E,\De)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{0}\) is satisfied, then \(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| = \infty\) holds true almost surely for all possible pairs \((\E,\De)\).
	
	4 - \(C_{\text{Fb}}\): \emph{Stabilization for Disturbed Plants.} The scenario is analogous to state estimation for disturbed plants. The task is to design a pair \((\E,\Dc)\)
	such that \(\limsup_{t\in\NN} \|\rs_t\| < \infty\) holds true almost surely. The the sequence of noise-like fluctuations may be bounded arbitrarily close to zero.
	If \(\eta(\mA) < C_{\text{Fb}}\) is satisfied, there exists a pair \((\E,\Dc)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{\text{Fb}}\) is satisfied, then \(\limsup_{t\in\NN} \|\rs_t\| = \infty\) holds true almost surely for all possible pairs \((\E,\Dc)\).
	
	\subsection{Channel Classification Problems}
	In the following, we use the star symbol '\(\star\)' as a placeholder. In light of the results established in \cite{MS07, MS07SC}, we define 
	the sets 
	\begin{align}	\S_\star(\mA) :&= \big\{ W \in \W(\X,\Y) : C_\star > \eta(\mA)\big\}, \\
					\U_\star(\mA) :&= \big\{ W \in \W(\X,\Y) : C_\star < \eta(\mA)\big\},
	\end{align}
	for \(\star \in \{\text{'\(0\)'},\text{'\(0,\mathrm{f}\)'}\}\) and \(\mA\in\RR^{n\times n}\).
	
	\begin{Remark}	Further variants of the remote state estimation and control problem that were also considered in \cite{MS07, MS07SC} 
					allow communication channels with feedback. However, this supplementary degree of freedom does not introduce an additional channel capacity. 
	\end{Remark} 

\section{Turing Machines and Effective Analysis}\label{sec:introTuring}
	
	\subsection{Background}
	\revision{Conservative approach: unless a positive proof (i.e., the channel is sufficient) is provided by the algorithm, the system
				must not operate.}
	
	In order to formalize the idea of algorithmic decidability, we employ the theory of Turing machines and, subsequently, 
	the theory of effective analysis, which is based on the former.	In \cite{BoBoDe21TAC}, we have applied the both theories to investigated the decidability of the problem of
	remote state estimation via noisy channels with respect to the objective of almost sure observability for disturbend plants, and with respect to the
	objective of observability with high probability for undisturbed plants. In order to provide a self contained work, we recapitulate the introduction 
	to Turing machines and effective analysis given in \cite{BoBoDe21TAC} in the following.
	
	\revision{Revise the last paragraph?}
	
	Turing machines were introduced in \cite{T37a,T38} in order to formalize the idea of computability. 
	The framework of Turing machines fully captures the theoretical limits of today's real-world digital computers. For \(n\in\NN\), a partial mapping \(f : \NN^n \part \NN\) 
	is referred to as recursive if and only if it can be computed on a Turing machine \cite{Kl36,T37b}. Hence, a function \(f :\NN^n \part \NN\) can, in principle, be 
	computed on a real-world digital computer if and only if it is recursive. 
	
	In the context of Turing machines, the partiality of recursive functions has a dedicated interpretation: for some partial recursive function \(f: \NN \part \NN\), 
	a number \(n\in\NN\) satisfies \(n\in D(f)\) if and only if the correspondig Turing machine \(\TM_f\) \emph{halts} and returns the value \(f(n)\) after a finite
	number of computing steps, whenever it receives the number \(n\) as input. In contrast, if \(n\) satisfies \(n\in \NN\setminus D(f)\), the Turing machine continues
	its computation forever, without ever reaching its halting state. 

	Applying the theory of Turing machines to the domain of real- and complex-valued analysis, we arrive at the 
	discipline of effective analysis. The latter will be the core ingredient in our investigation of the RSE problem. 
	For a comprehensive treatment of the topic, we refer to \cite{PoRi17,AB14}.%\FormatExtra{}{\pagebreak}

	\begin{Definition}  \label{ber}
						A sequence of rational numbers \((r_n)_{n\in\NN}\) is called computable if there exist recursive functions \(a,b,s:\NN\to\NN\), such that
						\begin{align*}   r_{n} = (-1)^{s(n)}\frac{a(n)}{b(n)} 
						\end{align*} 
						holds true for all \(n\in\NN\).
	\end{Definition}

	\begin{Definition}  \label{compreal}
						A number \(x\in\RR\) is called computable if there exists a computable sequence of rational numbers 
						\(\mathfrak{r} = (r_n)_{n\in\NN}\) such that \(|x-r_n|<2^{-n}\) holds true for all \(n\in\NN\). We denote the set of computable real numbers by \(\RRc\).
	\end{Definition}

	\begin{Remark}  A number \(x\in\RRc\) is computable if and only if there is a computable sequence \((r_n)_{n\in\NN}\) 
					of rational numbers and a recursive function \(\xi:\NN\to\NN\), such that \(|x-r_n|< 2^{-N}\)
					holds true for all \(n,N\in\NN\) that satisfy \(n \geq \xi(N)\). 
	\end{Remark}

	\noindent A computable sequence \(\mathfrak{r} = (r_n)_{n\in\NN}\) of rational numbers that satisfies \(|x-r_n|<2^{-n}\) for some number \(x\in\RRc\) 
	is referred to as a standard description of the number \(x\), which we denote by \(\mathfrak{r}\sim x\) in formal expressions. 
	
	\begin{Definition}	A sequence \((x_n)_{n\in\NN}\) of computable numbers is called computable if there exists a computable double-sequence
						\((r_{n,m})_{n,m\in\NN}\) of rational numbers such that 
						\begin{align} (r_{n,m})_{m\in\NN} =: \mathfrak{r}_n \sim x_n
						\end{align}
						holds true for all \(n\in\NN\).
	\end{Definition}
	
	In analogy to standard descriptions of computable numbers, the sequence \((\mathfrak{r}_n)_{n\in\NN}\) is referred to as a standard description
	of the sequence \((x_n)_{n\in\NN}\).

	Computable numbers can alternatively be characterized by computable sequences of rational numbers that satisfy monotonicity conditions. 
	In particular, there exists a Turing machine \(\TM_{\mathrm{std}\rightarrow\mathrm{alt}}\) that returns a pair \((\vec{\mathfrak{r}}, \cev{\mathfrak{r}})\) 
	whenever it receives a standard description \(\mathfrak{r}\) of some number \(x\in\RRc\) as input, such that
	\(	\vec{r}_n \leq \vec{r}_{n+1} \leq x \leq \cev{r}_{n+1} \leq \cev{r}_n
	\)
	as well as 
	\(	| \cev{r}_n - \vec{r}_n\hspace{1pt}| < 2^{-n}
	\)
	are satisfied for all \(n\in\NN\). Likewise, there exists a Turing machine \(\TM_{\mathrm{alt}\rightarrow\mathrm{std}}\) that returns a standard description 
	\(\mathfrak{r}\) of that number whenever it receives an alternative description \((\vec{\mathfrak{r}}, \cev{\mathfrak{r}})\) in the above sense as input. 
	For a more in-depth discussion, we again refer to \cite{PoRi17}. %\marker{\(\leftarrow\) Check This}

	The definition of computable numbers allows for the extension of the theory of computability to the realm of functions on the real numbers, 
	leading to the discipline of computable analysis. There are different approaches towards a formalization of computability on the reals; for a comparison 
	we refer to \cite{AB14}. We introduce the notions of \emph{Banach-Mazur} and \emph{Markov computability}, which is suitable for our purposes. 

	\begin{Definition}  \label{Borel}
						A function \(f : \RRc \to \RRc\) is called Banach-Mazur computable %\marker{\(\leftarrow\) Check This} 
						if for every computable sequence \((x_n)_{n\in\NN}\) of computable numbers, the sequence
						\((f(x_n))_{n\in\NN}\) is in turn a computable sequence of computable numbers.
	\end{Definition}
	
	\begin{Definition}  \label{Borel}
						A function \(f : \RRc \to \RRc\) is called Markov computable %\marker{\(\leftarrow\) Check This} 
						if there exists a Turing machine \(\TM_f\) that returns a standard description
						of the number \(f(x) \in \RRc\) whenever it receives a standard description of the number \(x\in \RRc\) as input.
	\end{Definition}
	
	\begin{Lemma}	Let \(f : \RRc \to \RRc\) be Markov computable. Then, \(f\) is Banach-Mazur computable.	
	\end{Lemma}\begin{proof}
					See \cite{AB14}.
	\end{proof}

	\noindent Since real-valued vectors and matrices are essentially multi-dimensional tuples of real numbers, the ideas of standard descriptions, computable sequences,
	Banach-Mazur computability and Markov computability naturally extend to the set \(\RRcP{n\times m} := (\RRc)^{n\times m}\) and vector/matrix-valued functions thereon. 
	Last but not least, we introduce a formal notion of decidability in the realm of computable \(n\times m\) - matrices \(\RRcP{n\times m}\):
	\revision{We need a definition of decidability with respect to \(\W\) and channel classification problems here.}
	\begin{Definition}  \label{semi}
						A set \(\A \subseteq \RRcP{n\times m}\) is called \emph{semi-decidable} as a subset of \(\RRcP{n\times m}\) 
						if there exists a Turing machine \(\TM_{\A}\) that reaches its halting state (and returns the value ``\(\mathtt{TRUE}\)") 
						after a finite number of computation steps if and only if it receives a standard description \(\mathfrak{A}\) of an element 
						\(\mA \in \RRcP{n\times m}\) that satisfies \(\mA\in\A\) as input. A set \(\A \subseteq \RRcP{n\times m}\) is called 
						\emph{decidable} as a subset of \(\RRcP{n\times m}\) if both \(\A\) and \(\overline{\A} := \RRcP{n\times m}\setminus\A\) are semi-decidable.
	\end{Definition} 
	
	\noindent The Turing machine \(\TM_\A\) is said to \emph{accept} standard descriptions \(\mathfrak{A}\) of elements \(\mA\in\A\).
	
	\revision{Decidability, recursiveness, the indicator function and their relation.}
	
	\subsection{Decidability of Channel Classification Problems}
	\begin{Lemma}	\label{lem:IndicatorFunctionBanachMazur}
					Let \(\X,\Y\) be finite Alphabets and \(\M_0, \M_1\) disjoint subsets of \(\Wc(\X,\Y)\) that satisfy the following:
					\begin{itemize}	\item There exist \(W_0\in\M_0\) and \(W_1\in\M_1\) such that for all \(\mu \in (0,1]\cap \RRc\), 													
										we have \((1-\mu)W_0 + \mu W_1 \in \M_1\). 
					\end{itemize}
					Then, the indicator-function \(\mathds{1}_{\M_0} : \M_0\cup \M_1 \rightarrow \RRc\) is \emph{not} Banach-Mazur computable.
	\end{Lemma}\begin{proof}
					We prove the claim by contradiction. Thus, assume the function \(\mathds{1}_{\M_0}\) is Banach-Mazur computable. Let 
					\(\N\subset \NN\) be a recursively enumerable, nonrecursive set and consider a recursive enumeration \(f_\N : \NN \rightarrow \N\)
					of \(\N\). For all \(n,m\in\NN\), define
					\begin{align}	g(n,m) := 	\begin{cases}	0 &\text{if~} n \in \big\{f_\N(l) : 1 \leq l \leq m\big\}, \\ 	
																1 &\text{otherwise}.
												\end{cases}
					\end{align}
					Then, \(g: \NN^2 \rightarrow \NN\) is a total recursive function that satisfies the following:
					\begin{itemize}	\item 	for all \(n,m,l\in\NN\) that satisfy \(m\leq l\), we have \linebreak \(g(n,m) = 0 \Rightarrow g(n,l) = 0\);
									\item	for all \(n\in\NN\), there exists \(m\in\NN\) such that \(g(n,m) = 0\) is satisfied if and only if 
											\(n\in \N\) holds true.
					\end{itemize}
					Next, define the computable double sequence \((r_{n,m})_{n,m\in\NN}\) of rational numbers via
					\begin{align}	r_{n,m} := 1 - \sum_{l = 1}^{m+1} g(n,l)\cdot 2^{-l}
					\end{align}
					for all \(n,m\in\NN\). Then, the sequence \((r_{n,m})_{n,m\in\NN}\) satisfies the following:
					\begin{itemize}	\item	we have \(\lim_{m\to\infty} r_{n,m} =: x_n \in [0,1]\) for all \(n\in \NN\);
									\item	for all \(n,m,l\in\NN\) with \(m < l\), we have either \(r_{n,m} < 2^{-m}\) or   
											\(r_{n,m} = r_{n,l}\). Hence, we have \(|x_n - r_{n,m}| < 2^{-m}\) for all \(n,m\in\NN\),
											making \((x_n)_{n\in\NN}\) a computable sequence of computable numbers with 
											\((r_{n,m})_{n,m\in\NN} \sim (\mathfrak{r}_{n})_{n\in\NN} \sim (x_n)_{n\in\NN}\);
									\item 	we have \(x_n = 0\) if and only if \(n\in\N\) is satisfied. 
					\end{itemize}   
					Now consider channels \(W_0\in\M_0\) and \(W_1\in\M_1\) as specified by the claim. Define the sequence \((V_n)_{n\in\NN}\) via
					\begin{align}	(1-x_n)W_0 + x_n W_1 =: V_n \in \Wc(\X,\Y).
					\end{align}
					Since multiplication and addition are Markov computable on \(\RRc\), the sequence \((V_n)_{n\in\NN}\) is a computable
					sequence of computable channels. Furthermore, for all \(n\in\NN\), we have \(V_n \in \M_0\) if and only if \(n\in\N\) holds true. 
					By assumption, the indicator function \(\mathds{1}_{\M_0}\) is Banach-Mazur computable. Hence, there exists a computable sequence
					\((\xp{n})_{n\in\NN}\) of computable numbers that satisfies
					\begin{align}	\xp{n}	&= 	\begin{cases}	1	&\text{if}~ V_n \in \M_0, \\
																0 	&\text{otherwise},
												\end{cases} \\
											&=	\begin{cases}	1	&\text{if}~ n \in \N, \\
																0 	&\text{otherwise}.
												\end{cases} 
					\end{align}
					Let \((\rp{n,m})_{n,m\in\NN}\) be a standard description of \((\xp{n})_{n\in\NN}\). Then, for all \(n\in\NN\), we have
					\begin{align}	\rp{n,1} 	\begin{cases}	> 2^{-1}	&\text{if}~ n \in \M_0, \\
																< 2^{-1} 	&\text{otherwise}.
												\end{cases} 
					\end{align}
					Hence, for the indicator function \(\mathds{1}_\N\) of \(\N\), we obtain
					\begin{align}	\mathds{1}_\N =		\begin{cases}	1	&\text{if}~\rp{n,1} > 2^{-1}, \\
																		0	&\text{otherwise}.
														\end{cases} 
					\end{align}
					Since \(\rp{n,1}\) is a rational number for all \(n\in\NN\), the predicate \(P(n) \equiv  \rp{n,1} > 2^{-1}\) can be
					evaluated effectively for all \(n\in\NN\), making \(\mathds{1}_\N\) a recursive function, which is a contradiction to the nonrecursivity of \(\N\).			
	\end{proof}
	\begin{Lemma}	\label{lem:SubsetNotSemidecidable}
					Let \(\X,\Y\) be finite Alphabets and \(\M_0, \M_1\) disjoint subsets of \(\Wc(\X,\Y)\) that satisfy the following:
					\begin{itemize}	\item There exist \(W_0\in\M_0\) and \(W_1\in\M_1\) such that for all \(\mu \in (0,1]\cap \RRc\), 													
										we have \((1-\mu)W_0 + \mu W_1 \in \M_1\). 
					\end{itemize}
					Then, the sets \(\M_0\) and \(\M_1\) are \emph{not} decidable as subsets of \(\M_0 \cup \M_1\). In particular, the set 
					\(\M_0\) is \emph{not} semi-decidable as subset of \(\M_0 \cup \M_1\).
	\end{Lemma}\begin{proof}
					We prove the claim by contradiction. Thus, assume the set \(\M_0\) is decidable as subset of \(\M_0 \cup \M_1\). 
					Then, there exists a Turing machine \(\TM_0\) that returns the value ``\(\mathtt{TRUE}\)" whenever it receives a standard description
					\(\mathfrak{W}\) of some channel \(W\in \M_0\) as input, and does \emph{not} halt otherwise. Observe that the mapping
					\begin{align}	\mu \mapsto W(\mu) := (1-\mu)W_0 + \mu W_1
					\end{align} 
					is Markov computable, since it constist exclusively of component-wise addidtions and multiplications, which in turn are Markov computable on \(\RR_c\).
					In other words, there exists a Turing machine \(\TM_{\mu\mapsto W}\) that returns a standard descritption \(\mathfrak{W}\) of 
					\(W(\mu)\) whenever it receives a standard description \(\mathfrak{m}\) of \(\mu\) as input. We have \(W(\mu) \in \M_0\) if and only if
					\(\mu = 0\) is satisfied. Thus, by concatenation, we obtain a Turing machine
					\(\TM_{=0}\) that satisfies
					\begin{align}	\mathfrak{m} \sim \mu \wedge \mu = 0	\quad\Leftrightarrow\quad  \TM_{=0}(\mathfrak{m}) = \mathtt{TRUE},
					\end{align}
					which is a contradiction to the undecidability of the \emph{halting} problem, see \cite{PoRi17}.
	\end{proof}
	
	\subsection{Banach-Mazur Computability in the Scope of System Verification}
	In the scope of system verification, Banach-Mazur computability has a noteworthy interpretation.
	For reasons of expedience, we will discuss this interpretation in the context of remote system control; the underlying principle can be 
	directly transferred to problems that are similar in structure.
	
	Consider a setup similar to the one depicted in Figure \ref{fig:Schematics}. An unstable, dynamic system is to be stabilized remotely via a control link.
	The remote controller observes the system via a DMC \(W\), which belongs to one of two disjoint sets \(\M_0\) and \(\M_0\). For example, the set \(\M_0\) may
	correspont to the set of \emph{critical} channels, that are insufficient for the remote stabilization of the system. In order to control the system automatically,
	an autonomous control tool is designed, which is required to initiate special actions if it detects the communication link to belong to the set \(\M_0\). For example,
	it might increase the transmission power to increase the quality of the channel, or, in extreme cases, shut down the system. For the sake of the argument, we
	do not require the autonomous control tool to meet any constraints regarding computability; rather, we think of it as a black-box that implements an arbitrary
	(but fixed) function that maps a set \(\M_0\cup \M_1\) to \(\{0,1\}\).
	
	Before such an autonomous control tool is put into operation, it is likely required to undergo a series of test to provide evidence for its functionality.
	A possible test bench is visualized in Figure \ref{fig:Verification}: the tool is fed with a series of automatically generated, artificial inputs 
	\begin{align}	V_1,V_2,V_3,\ldots \in (\M_0\cup \M_0) \cap \Wc(\X,\Y), 
	\end{align}
	while the tool's output is compared to a target value by a verifier. 
	\begin{figure}\linespread{1} %Put everything in box: Testbench
		\centering
		\begin{tikzpicture}[scale = 0.7, every node/.style={scale=0.7}]
			%   %   %   %   %   %   %   %   %   %   %
			%   Input Generator
				\fill[fill=black!15, rounded corners=0.1cm] (-5,2) rectangle (-3,0);
				\draw (-4, 1)  node[anchor=center] {\((V_n)_{n\in\NN} \vphantom{\Bigg|}\)};
				\draw (-4,2)  node[anchor=south] {Input Generator};
			%   %   %   %   %   %   %   %   %   %   %
			%   Autonomous Decision-Maker
				\draw[thick, fill=black!25] (-1,2) rectangle (1,0);
				\draw (0, 1)  node[anchor=center] {\(V_n \overset{\hspace{2pt}?}{\in} \M_0 \vphantom{\Bigg|}\)};
				\draw (0,2)  node[anchor=south, align = center] {Autonomous\\ Decision-Maker};
			%   %   %   %   %   %   %   %   %   %   %
			%   Verifier
				\fill[fill=black!15, rounded corners=0.1cm] (3,2) rectangle (5,0);
				\draw (4, 1)  node[anchor=center] {\(\overset{?}{=}\substack{\text{Target}\\\text{Value}}\vphantom{\Bigg|}\)};
				\draw (4,2)  node[anchor=south] {Verifier};
			%   %   %   %   %   %   %   %   %   %   %
			%   Test Cases
				\draw[very thick, ->, shorten >=1.5pt] (-0.1,-1.2) -- (-0.1,-0.7) -- (-4,-0.7) -- (-4,0); 
				\draw[very thick, ->, shorten >=1.5pt] (0.1,-1.2) -- (0.1,-0.7) -- (4,-0.7) -- (4,0);
				\draw (0,-1.2)  node[anchor=north]
				{\(n= 1,2,3,\ldots\)};
				\draw (0, -0.7)  node[anchor=south]
				{Test Cases};
			%   %   %   %   %   %   %   %   %   %   %
			%   Input Generator -> Autonomous Decision-Maker
				\draw[very thick, ->, shorten >=1.5pt] (-3,1) -- (-1,1.); 
				\draw (-2,1)  node[fill = white, anchor=center]
				{\(V_n\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Autonomous Decision-Maker -> Verifier
				\draw[very thick, ->, shorten >=1.5pt] (1,1) -- (3,1.); 
				\fill[fill = white] (1.6,1.5) rectangle (2.4, 0.5);
				\draw (1.7,1) -- (2.3,1); 
				\draw (2,1)  node[anchor=south]
				{\(\mathtt{YES}\)};
				\draw (2,1)  node[anchor=north]
				{\(\mathtt{NO}\)};				
		\end{tikzpicture}
		\caption{Interpretation of Banach-Mazur computability in the context of (semi-automated) system verification.}
		\label{fig:Verification}
	\end{figure}
	
	Provided that the sequence of test cases \((V_n)_{n\in\NN}\) is digitally generated and the indicator function \(\mathds{1}_{\M_0}\) is Banach-Mazur computable, 
	it is always possible to implement a digital verifier that generates the sequence 
	\begin{align} 	\mathds{1}_{\M_0}(V_1), \mathds{1}_{\M_0}(V_2), \mathds{1}_{\M_0}(V_3),\ldots	\in \{0,1\} 
	\end{align}
	of \emph{correct} target values,
	which can then be compared to the autonomous control tool's output. Unless the indicator function \(\mathds{1}_{\M_0}\) is Turing computable, an individual verifier has to be implemente for each 
	possible sequence of test cases. If, on the other hand, the indicator function \(\mathds{1}_{\M_0}\) is not Banach-Mazur computable, it is not generally possible to generate the 
	sequence of correct target values on digital hardware. In other words, for some sequences \((V_n)_{n\in\NN}\), there may not exist a digital verifier at all in this case.

\section{Blum-Shub-Smale Theory}	\label{sec:PreliminariesBSS}

	\subsection{Background}
	\revision{Despite the fact that the capabilities real-world, digital computers are 
	entirely captured by Turing machines, BSS machines over \(\RR\) are regularly considered in numerics and computational complexity theory. 
	This practice is justified by the premise that the error emerging from representing real numbers by floating point approximations is neglectible in all practically relevant numerical problems. 
	Furthermore, assumptions on the underlying machine model are usually implicit in numerics. In contrast, we seek to explicitly treat the underlying machine model in our investigations.}
			
	Blum-Shub-Smale (BSS) machines formalize the notion of computability over a field \(\FF\). The latter is assume to be equipped 
	with a binary relation \(\diamond~{:}~\FF \times \FF \rightarrow \{\mathsf{T},\mathsf{F}\}\), which is either an equality, equivalence or strict total order. 
	
	Despite the so called Church-Turing thesis being widely accepted as true, which implies that the capabilities of real-world computers are exactly characterized 
	by the abstract Turing machine, BSS machines are often implicitly considered as the underlying machine model in numerics and complexity theory. 
	A reason for this practice may lie in the ability of BSS machines to handle exact real numbers. Since most areas of applied mathematics involve continuous structures, 
	treating the content of a computer's memory as actual real numbers simplifies the description of algorithms to a great extent. For a detailed discussion on the Topic, we refer to \cite{Bl04}.

	In essence, BSS machines can be considered a generalization of Turing machines. They are equipped with a two-way infinite tape divided into cells, each of which holds an 
	element of \(\FF\cup\{\sqcup\}\). Here, "\(\sqcup\)" denotes the distinguished empty-space symbol. We assume that the tape is almost empty, i.e., all but finitely many cells 
	contain the symbol "\(\sqcup\)", at the beginning of the computation. A BSS machine interacts with its tape by means of a read-write head, which can, depending on tis current 
	position, access a fixed number of contiguous cells at a time. The algorithm executed by the BSS machine is characterized by its program, a finite, directed, simple graph 
	\begin{align*}   \G_\BSS = ([M_\BSS]_{0}, \V_\BSS),~ \V_\BSS \subseteq [M_\BSS]_{0} \times [M_\BSS],
	\end{align*} 
	with five types of nodes: \emph{input nodes}, \emph{computation nodes}, \emph{branching nodes}, \emph{shifting nodes} and \emph{output nodes}, each of which specifies a class 
	of fundamental machine operations. For a given input, the program flow corresponds to a directed walk in the program graph
	\begin{align*}	\F := (e_t)_{t\in\{1,2,\ldots,T\}},~T\in\NN\cup \{\infty\},
	\end{align*}
	starting from the input node and (possibly) ending in some output node, or continuing infinitely. In each step, the operation associated to the current node is executed, 
	affecting the content of the tape, the position of the read-write head and the program flow accordingly. Furthermore, the values stored in the initially non-empty cells 
	of the tape are considered part of the algorithm, much like hard-coded constants in a real-world computer program. 

	In order to prove that some problem is BSS-computable, on has, in principle, to provide the existence of a suitable program graph and, possibly, a tape with predefined constants. 
	This can often be cumbersome, since it involves the exact specification of the movement of the read-write head. If the size of the \emph{memory} required to execute the program, i.e., 
	the number of different cells accessed throughout the program execution, can be uniformly upper bounded by a number \(J_\BSS \in \NN\), we can get rid of the tape altogether by 
	introducing \emph{register variables} and \emph{constants},
	\begin{align*}	\bm{r} :&= (r_j^t)_{j\in\{1,\ldots,J_{\mathrm{R}}\}, t\in\{1,\ldots,T\}},\\
					\bm{c} :&= (c_j)_{j\in\{J_{\mathrm{R}} + 1,\ldots,J_{\mathrm{C}}\}},
	\end{align*}
	with \(T\in\NN\cup\{\infty\}\) and \(J_{\mathrm{C}} \leq J_\BSS\). The program graph then consists only of an input node, computation nodes, branching nodes and at least one output node.
	Furthermore, the corresponding classes of fundamental machine operations can be specified as follows:
	
	1 - \emph{Input nodes.} The unique input node \(\iota = e_1 = 0\) is associated to an 
		input operation \(g_\iota\). The input operation writes each component of a tuple 
		\begin{align*} 	\bm{a} = \big(a_1,a_2,\ldots a_{K({\bm{a}})}\big) \in {\bigcup}_{j=1}^{J_{\mathrm{R}}} \FF^{j}
		\end{align*}
		to the machine's internal registers \(\bm{r}\), according to the specification
		\begin{align*}	r^1_{j(k)} := a_k ,~ j(k)\in \{1,\ldots,J_{\mathrm{R}}\},~ k\in \{1,\ldots K(\bm{x})\}.   
		\end{align*}
		The remaining registers are initialized with the value\linebreak \(0 \in \FF\).
		There exists a unique next node \(\iota' \in [M_\BSS]\) to \(\iota\).
	
	2 - \emph{Computation nodes.} The program graph may contain a number of computation nodes \(\zeta \in \{1,2,\ldots M_{\mathrm{C}}\}\),    
		\linebreak \(M_{\mathrm{C}} \leq M_{\BSS}\), each of which is 
		is associated to a mapping 
		\( 	g_\zeta : \FF^{J_{\mathrm{C}}}\rightarrow \FF^{J_{\mathrm{R}}}, 
		\) 
		which is either polynomial, rational or has previously been shown to be BSS computable. The latter accounts for the fact that in the general, 
		unbounded setting, the program of some BSS machine can always be incorporated as a subroutine into the program of another BSS machine.
		If \(e_t = \zeta\) for some \(t\in\{1,\ldots, T-1\}\), we have
		\begin{align*}  \bm{r}^{t+1} = g_{\zeta}(\bm{r}^t,\bm{c})~\text{with}~\bm{r}^t := (r_j^t)_{j\in\{1,\ldots,J_{\mathrm{R}}\}}.
		\end{align*}
		There exists a unique next node \(\zeta' \in \{1,2,\ldots M_{\mathrm{C}}\}\) to each computation node \(\zeta\).
	
	3 - \emph{Branching nodes.}  A program may contain a number of branching nodes \(\beta \in \{M_{\mathrm{C}} + 1, M_{\mathrm{C}} + 2,\ldots, M_\mathrm{B}\}\), 
		each of which leave the content of the internal registers unchanged. That is, if \(e_t = \beta\) for some \(t\in\{1,\ldots, T-1\}\), we have
		\(\bm{r}^{t+1} = \bm{r}^{t}\). There exist exactly two next nodes \(\beta'(\mathsf{T})\) and \(\beta'(\mathsf{F})\) to each branching node \(\beta\). If 
		\(	\diamond\big(0, r^t_{j'(\beta)}\big) = \mathsf{T} 
		\)
		holds true for \(j'(\beta) \in \{1,\ldots, J_\mathrm{R}\}\), the program flow branches to the node \(\beta'(\mathsf{T})\). Otherwise, it moves to \(\beta'(\mathsf{F})\). 
		That is, for \(\beta = e_t\), we have
		\begin{align*}   e_{t+1} =   \begin{cases}   \beta'(\mathsf{T})  &\text{if}~\diamond\big(0,r^t_{j'(\beta)}\big) = \mathsf{T},\\
													\beta'(\mathsf{F})  &\text{otherwise}.
									\end{cases}    
		\end{align*}
		
	4 - \emph{Output nodes.} Each program contains at least one output node \(\sigma \in \{M_{\mathrm{B}} + 1, M_{\mathrm{B}} + 2,\ldots, M_\BSS\}\), 
		each of which is associated to an output mapping
		\(	o_\sigma : \FF^{J_{\mathrm{C}}}\rightarrow \FF^{J_{\sigma}}.
		\)
		For some fixed subset \(\J_\sigma\) of \([J_\mathrm{C}]\) and \(e_t = e_T = \sigma\), \(T\in\NN\), the mapping outputs (by projection) the values of the 
		register variables \((r_j^T)_{j\in \J_\sigma \cap \{1,\ldots,J_\mathrm{R}\}}\) and constants \((c_j)_{j\in \J_\sigma \cap \{J_\mathrm{R}+1,\ldots,J_\mathrm{C}\}}\). 
		There exists no next node to \(\sigma\).

	In our case, the field \(\FF\) will be the real numbers \(\RR\) with the usual strict total order "\(<\)". If \(\FF\) equals \(\mathbb{Q}\),
	%\(\ZZ_2\) (the set of boolean values with logical con- and disjunction as field operations), 
	the traditional theory of computation as formalized by Turing machines is recovered. For the remainder of this article, we will refer to BSS machines over \(\RR\) 
	simply as BSS machines, omitting the explicit mention of the field \(\FF\) being equal to the real numbers. 
	
	\subsection{Computing the Zero-Error and Feedback Zero-Error Capacity on BSS-Machines}
	\revision{Computing the Zero-Error capacity is an unsolved problem on Turing machines!}
	\noindent In the following, we specify a BSS-Algorithm which, for fixed alphabets \(\X\) and \(\Y\), computes the zero-error capacity \(C_0(W)\) 
	upon being passed a channel description \(W \in \W(\X,\Y)\). 

	Essentially, the algorithm relies on the fact that a \emph{lookup table} containing all possible values of \(C_0(W)\) can be hard-coded into the program. The lookup is performed in 
	terms of a perfect binary tree, where each branch corresponds to an evaluation of the predicate "\(W(y|x) > 0\)" for some letters \(x\in\X\) and \(y\in\Y\). Per definition, the latter 
	can be done algorithmically, as a fundamental operation on the BSS machine.

	\begin{Theorem}	\label{thm:ZeroErrorBSScomputable}
					Consider finite alphabets \(\X\) and \(\Y\). Then, there exists a BSS-Machine \(\BSS_{C_0}\)
					which, upon being passed a channel description \(W\in \W(\X,\Y)\), computes the mapping \(W \mapsto C_0(W)\).
	\end{Theorem}\begin{proof}
					Let \(j \mapsto \big(x(j), y(j)\big)\) be an enumeration of the set \(\X\times\Y\) and define
					\(J_\mathrm{R} := |\X\times \Y|\). Furthermore, consider the mappings
					\begin{align*}	\delta(W,j) :&=     \begin{cases}   1   &\text{if}~ 0 < W\big(y(j)|x(j)\big), \\
																		0   &\text{otherwise},
														\end{cases}\\
									\Delta(W)   :&=     1 + {\sum}_{j=1}^{J_\mathrm{R}} \delta(W,j)\cdot 2^{j-1} \in \big\{1,\ldots,2^{J_\mathrm{R}}\big\}.
					\end{align*} 
					We observe that, as a direct consequence of Theorem \ref{thm:ZE_Capacity}, the value of \(C_0(W)\) is 
					entirely determined by the set 
					\begin{align*}   \{(x,y) \in \X\times \Y : W(x|y) > 0\} \subseteq \X\times\Y
					\end{align*} 
					and hence, the zero-error capacity of \(W\) depends exclusively on the number \(\Delta(W)\). Thus, we obtain the existence of a mapping
					\(C'_0 : \big\{1,\ldots,2^{J_\mathrm{R}}\big\} \rightarrow \RR_0^+,~ \Delta \mapsto C'_0(\Delta),        
					\)
					such that \(C'_0(\Delta(W)) = C_0(W)\) holds true for all \(W\in\W(\X,\Y)\). For \(J_\mathrm{C} := J_\mathrm{R} + 2^{J_\mathrm{R}}\), 
					hardcode the family of constants \(\bm{c}\) according to 
					\(  c_j := C'_0(j - J_\mathrm{R})
					\)
					for all \(j\in \{J_\mathrm{R} + 1, \ldots, J_\mathrm{C}\}\) and specify the program \(\G = ([M_\BSS],\V_\BSS)\) with
					\begin{align*}	M_\mathrm{C} := 0,~M_\mathrm{B} := 2^{J_\mathrm{R}} - 1,~ M_\BSS := ~M_\mathrm{B} + 2^{J_\mathrm{R}}
					\end{align*}
					in the following way:
					\begin{enumerate}	\item[\(\iota\)\hspace{1pt}:] Preallocate the machine's registers \(\bm{r} := \bm{r}^1\) according to
											\(r_j := r^1_j := W\big(y(j)|x(j)\big)\) and set \(\iota' := 1\). Since the program does not contain any computation nodes,
											the content of the registers remains constant during the execution. We thus omit the superscript of the
											register variables in the following.
										\item[\(\beta\)\hspace{1pt}:] 
											For \(\beta \in \{1,\ldots, M_\mathrm{B}\}\), the pair of next nodes \(\big(\beta'(\mathsf{T}),\beta'(\mathsf{F})\big)\) satisfies
											\(	\beta'(\mathsf{T}) :    =  2\beta + 1, \quad
												\beta'(\mathsf{F}) :    =  2\beta.
											\)
											Denote \(m\in\NN\) the smallest natural number such that \(\beta < 2^m\) is satisfied. If, for some \(t\in\{1,\ldots, T-1\}\), we have
											\(e_t = \beta\), then \(e_{t+1}\) satisfies
											\begin{align*}   e_{t+1} := \begin{cases}	\beta'(\mathsf{T}) &\text{if}~ 0 < r_m,\\
																						\beta'(\mathsf{F}) &\text{otherwise}.
																		\end{cases}
											\end{align*}
										\item[\(\sigma\)\hspace{1pt}:] For \(\sigma \in \{M_\mathrm{B} +1, M_\BSS\}\), set \(j(\sigma) := \sigma - M_\mathrm{B} + J_\mathrm{R}\) 
											and return \(c_{j(\sigma)}\).
					\end{enumerate}
					Then, the BSS machine \(\BSS_{C_0}\) characterized by the triple \((\bm{r}, \bm{c}, \G)\) computes the mapping \(W\mapsto C_0(W)\).
	\end{proof}
	
	\revision{ Semi-algebraic sets!}

\section{Decidability Analysis}	\label{sec:DecidingRemoteStateEstimationOnBSS}
	
	\subsection{Decidability analysis of the RES Problem for Turing Machines}
	In this section, we will use Theorem \ref{thm:ZeroErrorBSScomputable} to derive a BSS algorithm which, given the description of an unstable, linear plant,
	decides the solvability of the remote state estimation problem as a function on \(\W(\X,\Y)\).
	
	Again, the algorithm essentially relies on the ability of BSS machines to handle exact real numbers. 

	\begin{Lemma} \label{lem:SstarSatisfiesProp}
		For \(\star \in \{\text{'\(0\)'},\text{'Fb'}\}\) and \(\mA\in\RRcP{n\times n}\) with \(\log_2\min\{|\X|,|\Y|\} > \eta(\mA) > 0\), there exists channels
		\(W_0 \in \S_\star(\mA)\cap \Wc(\X.\Y)\) and \(W_1\in \U_\star(\mA)\cap\Wc(\X,\Y)\), such that for all \(\mu\in (0,1]\cap\RRc\), 
		we have
		\begin{align}	(1-\mu)W_0 + \mu W_1 \in \U_\star(\mA)\cap\Wc(\X,\Y).
		\end{align}  
	\end{Lemma}\begin{proof}
		Observe that for \(W\in\W(\X,\Y)\) both the zero-error and the feedback zero-error capacity are entirely determined by the set
		\begin{align*}   \Omega(W) := \{(x,y) \in \X\times \Y : W(x|y) > 0\} \subseteq \X\times\Y.
		\end{align*}
		For details, see \cite{Sh56}. In particular, we have 
		\begin{align}	\Omega(W) = \X\times\Y \quad \Rightarrow \quad C_\star(W) = 0.
		\end{align}
		Furthermore, for all (nonempty) finite alphabets \(\X\) and \(\Y\), there exists a channel 
		\(\W_0\in \Wc(\X,\Y)\) that satisfies 
		\begin{align}	C_\star(W) = \log_2 \min \{|\X|,|\Y|\}.
		\end{align}
		By assumption, \(\eta(\mA) < \log_2 \min \{|\X|,|\Y|\}\) holds true. Thus, we have \(\W_0\in \S_\star(\mA)\).
		For all \((x,y)\in\X\times \Y\), define
		\begin{align}
			W_1(y|x) := \frac{1}{|\Y|}.
		\end{align}
		Then, we have \(\Omega(W_1) = \X\times \Y\), and thus \(C_\star(W_1) = 0\). Hence, \(W_1 \in \U_\star(\mA)\cap \Wc(\X,\Y)\)
		is satisfied. Now define
		\begin{align}
			W(\mu) := (1-\mu)W_0 + \mu W_1.
		\end{align}
		For all \(\mu \in (0,1]\cap\RRc\), we have \(\Omega(W(\mu)) = \X\times\Y\) and thus \(C_\star(W(\mu)) = 0\).
		Hence, \(W(\mu) \in \U_\star(\mA)\cap\Wc(\X,\Y)\) is satisfied for all \(\mu \in (0,1]\cap\RRc\).
	\end{proof}
	
	\begin{Theorem}
		For \(\star \in \{\text{'\(0\)'},\text{'Fb'}\}\), (nonempty) finite alphabets \(\X\) and \(\Y\) and
		\(\mA\in\RRcP{n\times n}\) with \(\log_2\min\{|\X|,|\Y|\} > \eta(\mA) > 0\), the indicator function \(\mathds{1}_{\S_\star(\mA) \cap \Wc(\X,\Y)}\)
		is not Banach-Mazur computable.
	\end{Theorem}\begin{proof}
		The claim is a direct consequence of Lemmata \ref{lem:IndicatorFunctionBanachMazur} and \ref{lem:SstarSatisfiesProp} and
		the observation that \((\S_\star(\mA) \cup \U_\star(\mA)) \cap \Wc(\X,\Y)\) is a nonempty subset of \(\Wc(\X,\Y)\).
	\end{proof}
	
	\begin{Theorem}
		For \(\star \in \{\text{'\(0\)'},\text{'Fb'}\}\), (nonempty) finite alphabets \(\X\) and \(\Y\) and
		\(\mA\in\RRcP{n\times n}\) with \(\log_2\min\{|\X|,|\Y|\} > \eta(\mA) > 0\), the set \(\S_\star(\mA) \cap \Wc(\X,\Y)\)
		is not semi-decidable as a subset of \(\Wc(\X,\Y)\).
	\end{Theorem}\begin{proof}
		The claim is a direct consequence of Lemmata \ref{lem:SubsetNotSemidecidable} and \ref{lem:SstarSatisfiesProp} and
		the observation that \((\S_\star(\mA) \cup \U_\star(\mA)) \cap \Wc(\X,\Y)\) is a nonempty subset of \(\Wc(\X,\Y)\).
	\end{proof}
	
	\subsection{Decidability analysis of the RES Problem for BSS-Machines}
	\begin{Theorem}	\label{thm:RemoteStateEstimationBSSDecidable}
					Let \(\X,\Y\) be finite alphabets and \(\mA \in \RR^{n\times n}\) a characterization of an unstable, time-invariant, 
					linear plant. Then, the following holds true:
					\begin{itemize}	\item There exists a BSS machine \(\BSS_{\S}^{\mA}\) that \emph{decides} the set
										\(\S_{\mA}(\X,\Y)\) as a subset of \(\W(\X,\Y)\). That is, we have
										\begin{align*}	\BSS_{\S}^{\mA}(W) = 	\mathds{1}_{\S_{\mA}(\X,\Y)}(W)
										\end{align*}
										for all \(\W(\X,\Y)\).
									\item There exists a BSS machine \(\BSS_{\U}^{\mA}\) that \emph{decides} the set
										\(\U_{\mA}(\X,\Y)\) as a subset of \(\W(\X,\Y)\). That is, we have
										\begin{align*}	\BSS_{\U}^{\mA}(W) = 	\mathds{1}_{\U_{\mA}(\X,\Y)}(W)
										\end{align*}
										for all \(\W(\X,\Y)\).
					\end{itemize}
	\end{Theorem}\begin{proof}
					Consider again an enumeration \(j \mapsto \big(x(j), y(j)\big)\) of the set \(\X\times\Y\) 
					Define \(M_\mathrm{C} := 1\), \(M_\mathrm{B} := 2\) and \(M_\BSS := 4\) as well as \(J_\mathrm{R} = \max\{|\X\times \Y|,3\}\) and 
					\(J_\mathrm{C} = J_\mathrm{R} + 1\). Furthermore, hard-code the sole constant \(c_{J_\mathrm{C}}\) according to
					\(c_{J_\mathrm{C} } := \eta(\mA)\) and specify the program \(\G = ([M_\BSS],\V_\BSS)\) in the following way:
					\begin{enumerate}	\item[\(\iota\)\hspace{1pt}:] Preallocate the machine's registers \(\bm{r}\) according to
											\begin{align}	r^1_j :=	\begin{cases}	W\big(y(j)|x(j)\big)	&\text{if}~ j\leq |\X\times\Y|,\\
																						0						&\text{otherwise}
																		\end{cases}
											\end{align}
											and set \(\iota' := 1\).
										\item[\(\zeta\)\hspace{1pt}:] For \(\zeta \in \{1,\ldots, M_\mathrm{C}\} = \{1\}\) and \(e_t = e_1 = \zeta\), set \(\zeta' = 2\) and define 
											\(\bm{r}^{t+1} = \bm{r}^{2} := g_1(\bm{c},\bm{r}^1).
											\)
										\item[\(\beta\)\hspace{1pt}:] 
											For \(\beta \in \{M_\mathrm{C} + 1,\ldots, M_\mathrm{B}\} = \{2\}\), the pair of next nodes \(\big(\beta'(\mathsf{T}),
											\beta'(\mathsf{F})\big)\) satisfies
											\(\beta'(\mathsf{T}) :    =  3\) and \(\beta'(\mathsf{F}) :    =  4\).
											If \(e_t = e_2 = \beta\), then \(e_{t+1} = e_T = e_3\) satisfies
											\begin{align*}   e_{3} := 	\begin{cases}   \beta'(\mathsf{T}) &\text{if}~ 0 < r_1^3,\\
																						\beta'(\mathsf{F}) &\text{otherwise}.
																		\end{cases}
											\end{align*}
										\item[\(\sigma\)\hspace{1pt}:] We have \(\sigma \in \{3,4\}\). For \(\sigma = 3\), return \(r_2^3\). For \(\sigma = 4\), return \(r_3^3\).
					\end{enumerate}
					Last but not least, consider the mappings
					\begin{align*}	g_1^\S(\bm{r}^t,\bm{c}) :&= \big(\BSS_{C_0}(\bm{r}^t) - c_{J_\mathrm{C}}, 1, 0, \ldots, 0\big), \\
									g_1^\U(\bm{r}^t,\bm{c}) :&= \big(c_{J_\mathrm{C}} - \BSS_{C_0}(\bm{r}^t), 1, 0, \ldots, 0\big), 
					\end{align*}
					where \(\BSS_{C_0}\) denotes the BSS-computable mapping that computes the zero-error capacity according to Theorem \ref{thm:ZeroErrorBSScomputable}. 
					Setting \(g_1 := g_1^\S\) yields a triple \((\bm{r}, \bm{c}, \G)\)
					that characterizes \(\BSS_{\S}^{\mA}\). Likewise, setting \(g_1 := g_1^\U\) yields a triple \((\bm{r}, \bm{c}, \G)\)
					that characterizes \(\BSS_{\S}^{\mA}\).
	\end{proof}
	
	The algorithm specified in the proof of Theorem \ref{thm:RemoteStateEstimationBSSDecidable} does not depend on \(\mA\) in a BSS-computable manner,
	since the number \(\eta(\mA)\) has to be hard-coded into the algorithm. In practical applications however, the characteristics of the plant
	are usually known during the design process, whereas only the channel is likely to vary during the operation
	of the system. Hence, the fact that for each system, an individual algorithm has to be designed, is not necessarily a drawback in this context.
	
\section{Summary and Additional Remarks}	\label{sec:Conclusion}
	In Section \ref{sec:introTuring}, we have introduced a class of binary channel classification problems  \(\M_j \subset \Wc : j \in \{0,1\}\) such that the case of \( j = 0\) is 
	not semi-decidable on a Turing Machine. With respect to this class of channel classification problems, we have shown that the indicator function 
	\(\mathds{1}_{\M_0} : \M_0 \cup \M_1 \rightarrow \{0,1\}\) is not Banach-Mazur computable, which we have discussed in the context of system verification.
	Furthermore, we have shown in Section \ref{sec:DecidingRemoteStateEstimationOnBSS} that the classification problem \((\S_\star(\mA),\U_\star(\mA)) = (\M_0,\M_1) : 
	\star \in \{\text{'\(0\)'},\text{'\(0,\mathrm{f}\)'}\}\), which characterizes the solvability of the remote state estimation and stabilization problem, belongs to this class. 
	In Section \ref{sec:PreliminariesBSS}, we have proven the existence of a Blum-Shub-Smale algorithm that computes the zero-error and/or feedback zero-error capacity
	\(C_\star : \W \rightarrow \RR_{\hspace{1pt}0}^{+}, \star \in \{\text{'\(0\)'},\text{'\(0,\mathrm{f}\)'}\}\) for channels \(W\in\W\). In turn, 
	we have used this result in Section \ref{sec:DecidingRemoteStateEstimationOnBSS} to provide a Blum-Shub-Smale algorithm that decides the classification problem
	\((\S_\star(\mA),\U_\star(\mA)) = (\M_0,\M_1) : \star \in \{\text{'\(0\)'},\text{'\(0,\mathrm{f}\)'}\}\).
	
	The Blum-Shub-Smale algorithms introduced in Sections \ref{sec:PreliminariesBSS} and \ref{sec:DecidingRemoteStateEstimationOnBSS} rely essentially on the 
	ability of Blum-Shub-Smale machines to process exact real numbers. As indicated in Sections \ref{sec:Introduction} and \ref{sec:PreliminariesBSS}, 
	the assumption of being able to perform exact computations within the continuous field \(\RR\) is common in engineering. It is usually made for reasons 
	of simplicity and despite the fact that the limits of real-world (digital) computing are characterized by the discrete Turing model. Remote state estaimation
	and stabilization is thus an applied example of the differing predictions provided by Turing and Blum-Shub-Smale theory with respect to the algorithmic
	solvability of mathematical problems.
	
	\revision{Computing zero-error capacity is hard for Turing machines; BSS machines can solve hard problems
	by "cheating", i.e., putting the solution to hard problems in their memory; inability of Turing machines to solve RES decidability problem
	is caused by first and foremost by inability to detect if a number equals zero; even if Turing machine is provided with additional information
	(e.g. confusability graph), decidability is still unclear, since C0 could still be an uncomputable number; BSS machines do not
	face this restriction for the abovementioned reason.}
	
	In the present work, the RES problem has been chosen as an example of use due to its inherent relevance to cyber-physical networks,
	which has been discussed in Section \ref{sec:Introduction}. The ``physical'' component in this scenario consists of the unstable LTI plant, which is an analog, 
	continuous system. The latter is true for the physical component of cyber-physical networks in almost all cases. Accordingly, the question arises as to 
	whether an implementation of the ``cyber'' component based solely on digital hardware will generally be sufficient.
	In recent years, we indeed observe a paradigm shift in research and development away from classical digital signal processing and computing hardware.
	Instead, the interest in analog technology experiences a revial, especially in the context of so-called \emph{neuromorphic computing}. 
	The question of how to model the computational capabilities of these technologies has not been conclusively resolved at the present time.
	In particular, a model for universal analog computing, comparable to the Turing machine for the digital domain, has not yet been widely accepted. 
	Such a characterization of universal neuromorphic computing may be related to the Blum-Shub-Smale model. In the broadest sense, the latter can be
	interpreted as a model for \emph{perfect} analog computing, i.e., in disregard of any imperfections or limitations on measurement resolution of real-world analog systems.
	Regarding practical implementations, there currently exist only individual examples of analog computation platforms, for example by Intel, IBM and Samsung.
	\revision{Provide a source for the last statement.}

	As indicated in the introduction, RES problems for undisturbed plants and an objective of observability/stabilizability with
	high probability were investigated in \cite{MS07SC}. The Shannon capacity \(C : \W \rightarrow \RR_{\hspace{1pt}0}^{+}\) was identified as the decisive quantity in this context.
	Consider a pair \((\E,\De\text{/}\Dc)\) of encoder and estimator/controller that estimates/stabilizes the state of some disturbed plant almost surely.
	Then, \((\E,\De\text{/}\Dc)\) also estimates/stabilizes the state of the same plant with (arbitrary) high probability, a fortiori, if the plant's state is 
	assumed to evolve free of noisy fluctuations. The converse is not true in general. Thus, mathematically speaking, the objective of almost sure 
	observability/stabilizability for disturbed plants is strictly stronger than the objective of observability/stabilizability with high probability for 
	undisturbed plants. This ``ordering'' is reflected in the relationship between the channel capacities relevant to each objective: we have
	\begin{align}
		C_0(W) \leq C_{0,\mathrm{f}}(W) \leq C(W)
	\end{align}
	for all \(W\in\W\). In \cite{BoBoDe21TAC}, the channel classification problem \((\S(\mA),\U(\mA) = (\M_0,\M_1)\) with
	\begin{align}	\S(\mA) :&= \big\{ W \in \W : C > \eta(\mA)\big\}, \\
					\U(\mA) :&= \big\{ W \in \W : C < \eta(\mA)\big\},
	\end{align}
	which corresponds to the objective of observability/stabilizability with high probability for 
	undisturbed plants, was shown to be decidable on a Turing Machine. 
	\revision{As indicated in Section \ref{sec:PreliminariesBSS},} The computational
	capabilities of Blum-Shub-Smale machines strictly exceed those of Turing machines, in the sense that any Turing machine can be emulated by a suitable
	Blum-Shub-Smale machine, but not vice versa. This leads to a noteworthy observation: the ordering between the differnt objectives not only reflects 
	in the relevant channel capacities, but also in the computational strength that is required to decide their satisfiability. 
	In essence, remote state estimation and stabilization is thus an example of what is often referred to as \emph{co-design} problem. It is characterized by
	an interplay of control engineering, information and network theory and hardware modeling, and does not decompose into subproblems from each of these fields
	that can be addressed individually. 	
		
%\section*{Acknowledgment}

\bibliographystyle{ieeetran}
\bibliography{ZeroErrorBSS}

\end{document}
