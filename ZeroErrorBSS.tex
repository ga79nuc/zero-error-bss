\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{mathtools,amssymb,amsfonts,amsthm,bm,dsfont}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{makecell}
% Bibliography Package
	\usepackage[numbers]{natbib}
% Custom Packages
	\usepackage{tikz}
% Custom Commands
	\newcommand{\rx}{\mathsf{x}}
	\newcommand{\ry}{\mathsf{y}}
	\newcommand{\rs}{\mathsf{s}}
	\newcommand{\rz}{\mathsf{z}}
	\newcommand{\ru}{\mathsf{u}}
	\newcommand{\rv}{\mathsf{v}}
	\newcommand{\rsh}{\hat{\mathsf{s}}}
	\newcommand{\rzs}{(\mathsf{z}_t)_{t\in\NN}}
	\newcommand{\rss}{(\mathsf{s}_t)_{t\in\NN}}
	\newcommand{\rus}{(\mathsf{u}_t)_{t\in\NN}}
	\newcommand{\rxs}{(\mathsf{x}_t)_{t\in\NN}} 
	\newcommand{\rys}{(\mathsf{y}_t)_{t\in\NN}}
	\newcommand{\rvs}{(\mathsf{v}_t)_{t\in\NN}} 
	\newcommand{\rshs}{(\hat{\mathsf{s}}_t)_{t\in\NN}}
	\newcommand{\part}{\hookrightarrow}
	\def\A{{\mathcal A}}
	\def\E{{\mathcal E}}
	\def\D{{\mathcal D}}
	\def\X{{\mathcal X}}
	\def\Y{{\mathcal Y}}
	\def\M{{\mathcal M}}
	\def\N{{\mathcal N}}
	\def\G{{\mathcal G}}
	\def\V{{\mathcal V}}
	\def\F{{\mathcal F}}
	\def\J{{\mathcal J}}
	\def\W{{\mathcal W}}
	\def\S{{\mathcal S}}
	\def\U{{\mathcal U}}
	\def\NN{{\mathbb N}}
	\def\QQ{{\mathbb Q}}
	\def\RR{{\mathbb R}}
	\newcommand{\RRc}{\RR_{\mathrm{c}}}
	\def\ZZ{{\mathbb Z}}
	\def\FF{{\mathbb F}}
	\def\CC{{\mathbb C}}
	\def\mM{\bm{\mathrm{M}}}
	\def\mA{\bm{\mathrm{A}}}
	\def\mC{\bm{\mathrm{C}}}
	\def\mB{\bm{\mathrm{B}}}
	\newcommand{\QE}{\mathcal{Q}_{\mathrm{E}}}
	\newcommand{\QD}{\mathcal{Q}_{\mathrm{D}}}
	\newcommand{\oQE}{\overline{\mathcal{Q}}_{\mathrm{E}}}
	\newcommand{\oQD}{\overline{\mathcal{Q}}_{\mathrm{D}}}
	\newcommand{\BSS}{\mathrm{BSS}}
	\newcommand{\TM}{\mathrm{TM}}
	\newcommand{\De}{\D_{\text{Est}}}
	\newcommand{\Dc}{\D_{\text{Ctrl}}}
	\newcommand{\cev}[1]{\reflectbox{\ensuremath{\vec{\reflectbox{\ensuremath{#1}}}}}}
	\newcommand{\RRcP}[1]{\mathrlap{\phantom{\RR}_{\mathrm{c}}}\RR^{#1}}
	\newcommand{\xp}[1]{\mathrlap{\phantom{x}^{\prime}}x_{#1}}
	\newcommand{\rp}[1]{\mathrlap{\phantom{r}^{\prime}}r_{#1}}
	\newcommand{\Wc}{\W_{\mathrm{c}}}
	\DeclareMathOperator{\Span}{Span}
	\newcommand{\rdummy}{{\color{red}[REF]}}
	\newcommand{\sdummy}{{\color{red}[SOURCE]}}
	\newcommand{\col}{\color{black}}
	\newcommand{\colol}{\color{orange}}
	%\newcommand{\tbr}[1]{{\color{gray}[#1]}}
	\newcommand{\tbr}[1]{}
	\newcommand{\noteholger}[1]{{\color{red}#1}}
% Custom Environments
	\newtheorem{Theorem}{Theorem}
	\newtheorem{Definition}[Theorem]{Definition}
	\newtheorem{Lemma}[Theorem]{Lemma}
	\newtheorem{Corollary}[Theorem]{Corollary}
	\newtheorem{Remark}[Theorem]{Remark}
%	%	%	%	%	
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
%
	\title{Algorithmic Aspects of Remote Control Problems:\\ Decidability on Digital and Real Number\\ Signal Processing Hardware
		%\thanks{H.~Boche was supported by the German Research Foundation (DFG) within
				%the Gottfried Wilhelm Leibniz Prize under Grant BO 1734/20-1, within
				%Germany’s Excellence Strategy EXC-2111—390814868 and EXC-2092 CASA -
				%390781972
				%and by the German Federal Ministry of Education and Research (BMBF)
				%within the national initiative for “Post Shannon Communication (NewCom)”
				%with the
				%project “Basics, simulation and demonstration for new communication
				%models” under Grant 16KIS1003K.
				%C.~Deppe was supported by the BMBF within NewCom with the project
				%“Coding theory and coding methods for new communication models” under
				%Grant 16KIS1005, by the German Research Foundation (DFG)
				%with the Project "Post-Shannon theory and implementation" under Grant DE
				%1915/2-1 and by the German Federal Ministry of Education and Research
				%(BMBF) within the project "6G-life" under Grant 16KISK002.}
	}
	\author{\IEEEauthorblockN{Holger Boche}
	\IEEEauthorblockA{\textit{Institute for}\\ 
	\textit{Theoretical Information Technology,}\\
	\textit{Technical University of Munich}\\
	Munich, Germany\\
	boche@tum.de\\
	ORCID: 0000-0002-8375-8946}
	\and
	\IEEEauthorblockN{Yannik Böck}
	\IEEEauthorblockA{\textit{Institute for}\\ 
	\textit{Theoretical Information Technology,}\\
	\textit{Technical University of Munich}\\
	Munich, Germany \\
	yannik.boeck@tum.de\\
	ORCID: 0000-0001-7640-6988}
	\and
	\IEEEauthorblockN{Christian Deppe}
	\IEEEauthorblockA{\textit{Institute for}\\
	\textit{Communications Engineering,}\\
	\textit{Technical University of Munich}\\
	Munich, Germany \\
	christian.deppe@tum.de\\
	ORCID: 0000-0002-2265-4887}
	}

\maketitle

\begin{abstract}
	We consider a decision problem associated to the task of estimating the state of a dynamic plant remotely via a noisy communication channel: 
	given the characteristics of some unstable LTI plant and some DMC, does there exist an encoder/decoder-pair that 
	allows for the remote tracking of the plant's state with bounded error? Questions of this kind are becoming increasingly important in communication technologies, 
	since future communication networks are expected to incorporate distributed control and decision making. Analytically, this problem has been shown to involve the 
	zero-error capacity of the DMC. Starting from this result, we approach the problem from the view of theoretical computer science, 
	with an explicit treatment of the underlying machine Model. In particular, we prove that for every pair of a finite channel input alphabet and a finite channel output alphabet, there exists
	a Blum-Shub-Smale algorithm that computes the zero-error capacity in dependence of the channel matrix. Based on this, we devise a Blum-Shub-Smale algorithm that solves the above 
	decision problem given the plant's and DMC's characteristics. Blum-Shub-Smale machines are a promising candidate for a universal model of real number processing hardware, comparable
	to the Turing machine in the digital domain. Recently, we observe an increased interest in research and development towards real number and/or analog computing hardware, usually
	referred to by the term ``neuromorphic computing''.   
\end{abstract}

\begin{IEEEkeywords}
	Co-Design of Communications and Control, Remote State Estimation, Noisy Channels, Neuromorphic Computing. 
\end{IEEEkeywords}

%\section{TO-DO}
	%\begin{itemize}
		%\item Check usage of \(j,J,k,K,l,L,\ldots\).
		%\item Check indents.
		%\item Sources and references.
		%\item Spellcheck.
		%\item Hypenation.
		%\item Emphasizement/Italic
		%\item \textbf{Revision.}
		%\item Conclusion (Why are results important?; Description on a BSS machine: BSS machines are able to handle exact descriptions, not ``representations of objects'',
				%as TMs do; Machine ethics; Big picture: other results on the topic; Different machine models lead to different results, making an explicit treatment of underlying
				%machine model necessary;).
		%\item ``Despite the fact..'': check styleguide.
		%\item ``BSS machines over \(\RR\) are regularly..'': check styleguide.
		%\item Almost sure stability.
		%\item Reference exact assumptions on \((\mA,\mB,W,\E,\D)\) and \((\rz_t)_{t\in\NN}\), \(\rs_{0}\).
		%\item Lemma \label{lem:SolvabilityCondition}: independent of distributions.
		%\item Sans-Serif versus normal notation (random variables versus realizations).
		%\item tbr Command!
	%\end{itemize}

%\tbr{Generally, remote and/or distributed decision making is becoming increasingly important in view of future communication networks. The ideas behin well known slogans like``Industry 4.0'', 
	%``Autonomous Driving'', ``Internet of Things'' and the ``Metaverse'' are examples for the currentd trend in communications to shift the focus away from pure data transmission 
	%towards interconnected information processing and control of agents that perform real world actions. Since technologies of this kind are potentially affecting human lives, 
	%strict rules for technology assessment are necessary. {\color{red} Der Übergang passt noch nicht...} For the upcoming 5G and 6G mobile communication standards,
	%explicite requirements regarding hardware trustworthiness and integrity are stated, some of which have been shown to exceed the limitations of today's digital hardware. 
	%At the same time, we can observe a recent paradigm shift in research and development towards analog signal processing and computing hardware, summarized under the slogan ``neuromorphic computing''. 
	%While the theoretical capabilities of digital hardware are precisely captured by the abstract model of Turing machines, a comparable universal model for analog computing has not been widely accepted. 
	%A promising candidate for the latter is the \emph{Blum-Shub-Smale} machine, a generalization of the Turing machine that can process exact real numbers. BSS machines have been shown to be more powerful
	%than Turing machines in general, with many specific instances of practical relevance. In particular, there are several scenarios in communication where BSS machines are more powerful than Turing machines.
	%Hence, BSS machines merit an investigation from a theoretical point of, even if they cannot be practically implementend as of today.}
	%\tbr{Given the rise of digital technology in control and decision making, questions of this kind become increasingly important, especially with regards to technology assessment and machine ethics.}

\section{Introduction}	\label{sec:Introduction}
	\IEEEPARstart{R}{emote} state estimation via noisy communication channels is a prominent problem in control theory 
	\cite{MS07, MS07SC, S06, SP03}. 
	The problem involves both control and communications. In particular, as we will see in the following, the communications part is essential.  
	Informally, the corresponding dynamic system can be described as follows. The state of an unstable linear time-invariant \emph{(LTI)} plant is observed by a local sensor. 
	Subsequently, the sensor data is feed into an encoder that prepares the data for transmission trough a discrete, memoryless channel \emph{(DMC)}. 
	Based on the sequence of channel outputs, the remote decoder/estimator tries to estimate the current state of the plant. The setup is schematically depicted in Figure \ref{fig:Schematics}.
	\begin{figure}\linespread{1}
		\centering
		\begin{tikzpicture}[scale = 0.7, every node/.style={scale=0.7}]
			%   %   %   %   %   %   %   %   %   %   %
			%   Initial state
				\draw[very thick, ->, shorten >=1.5pt] (-4.5,1.75) -- (-2,1.75); 
				\draw (-3.25,1.75)  node[fill = white, anchor=center, align=center]
				{\(\rs_0\)};
				\draw (-4.5,1.75)  node[fill = white, anchor=center, align=center]
				{\(\dots\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Plant disturbance
				\draw[very thick, ->, shorten >=1.5pt] (-4.5,1.25) -- (-2,1.25); 
				\draw (-3.25,1.25)  node[fill = white, anchor=center, align=center]
				{\(\rzs\)};
				\draw (-4.5,1.25)  node[fill = white, anchor=center, align=center]
				{\(\dots\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Plant
				\draw[thick, fill=black!25] (-2,2) rectangle (0,1);
				\draw (-1,1.5)  node[anchor=center] {\(\mA\)};
				\draw (-1,2)  node[anchor=south] {Plant};
			%   %   %   %   %   %   %   %   %   %   %
			%   Plant -> Sensor
				\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (0,1.5) -- (2.5,1.5); 
				\draw (1.25,1.5)  node[fill = white, anchor=center]
				{\(\rss\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Sensor
				\draw[thick, fill=black!25] (4.5,2) rectangle (2.5,1);
				\draw (3.5,1.5)  node[anchor=center] {\(\mB\)};
				\draw (3.5,2)  node[anchor=south] {Sensor};
			%   %   %   %   %   %   %   %   %   %   %
			%   Sensor -> Encoder
				\draw[very thick, <-, shorten >=1.5pt, shorten <=1.5pt] (4,-1) -- (4,1); 
				\draw (4,0)  node[fill = white, anchor=center, align=center]
				{\(\rus\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Encoder
				\fill[fill=black!15, rounded corners=0.1cm] (4.5,-2) rectangle (2.5,-1);
				\draw (3.5,-1.5)  node[anchor=center] {\(\E\)};
				\draw (3.5,-2)  node[anchor=north] {Encoder};
			%   %   %   %   %   %   %   %   %   %   %
			%   Encoder -> Channel
				\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (2.5,-1.5) -- (-0.3,-1.5); 
				\draw (1.25,-1.5)  node[fill = white, anchor=center, align=center]
				{\(\rxs\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Channel
				\draw[thick, fill = black!25] (-2,-1.5) -- (-1.7, -1.1) -- (0,-1.1) -- (-0.3,-1.5) -- (0,-1.9) -- (-1.7,-1.9) -- (-2,-1.5);
				\draw (-1,-1.5)  node[anchor=center] {\(W\)};
				\draw (-1,-2)  node[anchor=north] {DMC};
			%   %   %   %   %   %   %   %   %   %   %
			%   Channel -> Decoder
				\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (-2,-1.5) -- (-4.5,-1.5); 
				\draw (-3.25,-1.5)  node[fill = white, anchor=center, align=center]
				{\(\rys\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Decoder
				\fill[fill=black!15, rounded corners=0.1cm] (-6.5,-2) rectangle (-4.5,-1);
				\draw (-5.5,-1.5)  node[anchor=center] {\(\De\)/\(\Dc\)};
				\draw (-5.5,-2)  node[anchor=north] {Estimator/Controller};
			%   %   %   %   %   %   %   %   %   %   %
			%   State estimate
				\draw[very thick, ->, shorten <=1.5pt] (-6,-1) -- (-6,1);
				\draw (-6,0)  node[fill = white, anchor=center, align=center]
				{\(\rshs\)};
				\draw (-6,1.5)  node[fill = white, anchor=center, align=center]
				{\(\vdots\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Control Link
				\draw[very thick, ->, shorten >=1.5pt, shorten <=1.5pt] (-5,-1) -- (-5,-0.5) -- (-1.5,0.5) -- (-1.5,1);
				\draw (-3.25,0)  node[fill = white, anchor=center, align=center]
				{\(\rvs\)};
		\end{tikzpicture}
		\caption{Schematics of the remote state estimation setup considered throughout this article. The setup is identical to the one introduced in \cite{BoBoDe21TAC}\tbr{{\color{red}\(\leftarrow\) Change to TAC!~}}.}
		\label{fig:Schematics}
	\end{figure}
	The key applications of this problem range from robotics over autonomous driving to general remote controlled systems \cite{FeBo21}. However, there exist fundamental 
	limits to the capabilities of autonomous systems and computer aided design tools, as has been shown in several instances \cite{BoBoDe21TAC}\tbr{{\color{red}\(\leftarrow\) Check this source!~}}. These fundamental limits essentially
	depend on the hardware in use. For digital hardware, the Turing machine determines the fundamental limits. In recent times, there has been an increasing interest in analog information processing.
	Here Blum-Shub-Smale machines are a good candidate for a universal computation model.
	
	In essence, the remote state estimation problem consists of designing a pair of encoder and decoder which allows for the estimation of the plant's state in a sufficient manner.
	Generally, this is known as the co-design of control and communication. In this context, the problem of remote state estimation via noisy channels is particularly interesting,
	since it is an example for a scenario where practically relevant control-performance criteria have an essential impact on the required communications performance.
	As was shown in \cite{MS07}, the strong objective of almost sure observability requires the zero-error capacity of the DMC, while a weakened form of the observability criterion can be achieved
	by the classical Shannon capacity of the DMC.
	According to this, it is necessary to decide, based on the specifications of the plant and the DMC, whether an appropriate pair of encoder and decoder can exist in the first place. 
	Nowadays, this decision is often made by automated design tools or autonomous control units, e.g., in automated driving, either in an explicit or implicit way. In recent times, 
	\emph{digital twins} emerged as a further technique for handling design problems of this kind in practical applications \cite{RaSaKv20,TaZhLiNe19}. 
	The approach is based on creating a full virtual copy of the system on a digital computer, which is then employed for optimization, control tasks and decision-making. 

	From an analytic point of view, remote state estimation involves the disciplines of control and information theory. As indicated above, it is an explicit example of a so 
	called co-design problem. The practice of automated design and autonomous control adds another layer to the problem. In almost all cases, dynamic plants are analog, continuous  systems, 
	whereas the operation of digital computers is based on discrete algorithms. Hence, the question of whether appropriate computer-based decision-making with respect to analog 
	dynamic systems is actually possible, arises naturally. Thus, the question arises whether digital hardware is the proper hardware platform for decision making of this kind. It has been shown
	that digital hardware is insufficient in several cases. The Blum-Shub-Smale model is suitable to investigate whether analog information processing hardware, e.g., neuromorphic computing
	processors, is more suitable for this task.

	Problems of the latter kind are traditionally investigated in the field of theoretical computer science and have not gained much attention in applied engineering until now. 
	On the other hand, we can observe increasing requirements on electronic systems regarding safety, secrecy and, in lack of a different term, ethical behaviour \tbr{\sdummy}. 
	A prominent example is the related discussion surrounding autonomous driving, which is recently taking place in the community of machine ethics and technology assessment \tbr{\sdummy}. 
	In order to obtain a qualified evaluation of whether some digitally controlled technological system meets the abovementioned requirements, it is necessary to precisely understand 
	the fundamental boundaries of digital technology. This, in turn, requires an explicit treatment of those aspects of digital technology that involve theoretical computer science.

	In this series of articles (c.f. \cite{BoBoDe21X} for a full survey), we aim to approach the decision problem related to remote state estimation and stabilization from the perspective 
	of theoretical computer science. In \cite{BoBoDe21TAC}\tbr{{\color{red}\(\leftarrow\) Change to TAC!~}}, we have considered the decision problem with regards to Turing machines. In this work, we instead discuss 
	\emph{Blum-Shub-Smale (BSS) machines} as the underlying machine model. Potentially, Blum-Shub-Smale machines yield a mathematical description of a universal analog computer.
	Regarding a practical implementation, however, there exist only individual examples of analog computation platforms, as, for example, from Intel, IBM and Samsung, until today. 
	
	Despite the fact that the capabilities real-world, digital computers are 
	entirely captured by Turing machines, BSS machines over \(\RR\) are regularly considered in numerics and computational complexity theory. 
	This practice is justified by the premise that the error emerging from representing real numbers by floating point approximations is neglectible in all practically relevant numerical problems. 
	Furthermore, assumptions on the underlying machine model are usually implicit in numerics. In contrast, we seek to explicitly treat the underlying machine model in our investigations.

	The outline of the remainder of this work is as follows. Sections \ref{sec:FormalEstimationSetup}, \ref{sec:PreliminariesBSS} and \ref{sec:PreliminariesZeroError} are dedicated to preliminaries. 
	In particular, we recapitulate the description of the remote state estimation setup in a formal manner and introduce the theory of Blum-Shub-Smale machines and zero-error coding.
	In Section \ref{sec:ComputingZeroErrorOnBSS}, we present a BSS algorithm which, for fixed channel input and output alphabets, computes the zero-error capacity as a function on 
	the set of channels. In \ref{sec:DecidingRemoteStateEstimationOnBSS}, we apply the results established in Section \ref{sec:ComputingZeroErrorOnBSS} to devise a BSS algorithm
	which, for a fixed characterization of the unstable plant, decides the solvability of the remote state estimation problem. 
	As already stated before the co-design of control and communication is of particular interest in this context, since the criterion for control performance, which is
	usually determined by the practical application, essentially determines the performance criterion for communication. Interestingly, the weakened form of the control performance criterion 
	is decidable on digital hardware, and thus requires not only a weaker communication performance, but also a weaker computation performance regarding decidability. 
	The paper closes with a subsumption of 
	our findings in Section \ref{sec:Conclusion}.
                                                                        
\section{Formal Description of the Remote State Estimation Setup}	\label{sec:FormalEstimationSetup}
	\noindent In to following, we give a formal description of the setup depicted in Figure \ref{fig:Schematics}, as well as a brief summary of 
	some relevant results concerning different variants of the related estimation and control problem. Originally, these were derived in \cite{MS07, MS07SC}.  
	
	As indicated in Section \ref{sec:Introduction}, 
	the remote state estimation and stabilization problem revolves around the state sequence \((\rs_t)_{t\in\NN}\) 
	of an unstable LTI system. The system's dynamics are modelled by means of a matrix \(\mA \in \RR^{n\times n}\), which governs the evolution of \((\rs_t)_{t\in\NN}\) 
	according to the set of equations 
	\begin{align*}	 \rs_{t+1}    	= \mA \rs_t + \rz_t + \rv_t, 
	\end{align*}
	Here, the sequence \((\rz_t)_{t\in\NN}\) accounts for noise-like disturbances in the system's state progression and the sequence \(\rvs\) incorporates a control input. 
	Furthermore, the inital state \(\rs_0\) is assumend to emerge randomly according to some probability measure. 
	The system status is continuously monitored by a local sensor, which is characterized by a matrix \(\mB\in\RR^{n\times m}\). The sensor relates the
	state sequence \((\rs_t)_{t\in\NN}\) to a sequence \(\rus\) of measurements, conforming to the set of equations
	\begin{align*}	\ru_t    = \mB \rs_t.
	\end{align*}  	
	Based on the avaiable sensor data, an encoder succesively chooses channel inputs from a finte alphabet \(\X\). Mathematically, this is captured by the relation
	\begin{align*}	\rx_t   = \E \big(t, (\ru_{t'})_{t'=1}^{t}\big) 							= \E\big(t, \ru_1,\ru_2,\ldots,\ru_t\big).
	\end{align*}
	The sequence of channel outputs \((\ry_t)_{t\in\NN}\) is a sequence
	of symbols from another finite alphabet \(\Y\), and is related component-wise to the sequence \((\rx_t)_{t\in\NN}\) by a conditional probability mass function
	\begin{align*}	W :~ \Y \times \X \rightarrow \RR_{\hspace{1pt}0}^+,~(y,x) \mapsto W(y|x).
	\end{align*}
	The triple \((\X,\Y,W)\) fully characterizes the behaviour of the communication unit, and is referred to as a \emph{discrete, memoryless channel} (DMC).
	Last but not least, at the receiving end, the plant's state sequence is estimated according to a relation
	\begin{align*}	\hat{\rs}_t  	&= \De\big(t, (\ry_{t'})_{t'=1}^{t}\big)  \\
									&= \De\big(t,\ry_1,\ry_2,\ldots,\ry_t\big).
	\end{align*}
	Depending on the specific objective, a control input 
	\begin{align*}	\rv_t  			&= \Dc\big(t, (\ry_{t'})_{t'=1}^{t}\big)  \\
									&= \Dc\big(t,\ry_1,\ry_2,\ldots,\ry_t\big)
	\end{align*}
	is generated, which is then fed back to the dynamic system via a control-loop. Otherwise, if the objective concerns the estimation
	of the state sequence, we set
	\begin{align}	\label{eq:No_Ctrl_Loop}
					\Dc\big(t,\ry_1,\ry_2,\ldots,\ry_t\big) = \bm{0}
	\end{align}
	for all \(t\in\NN\), where \(\bm{0}\) denotes the \emph{zero-vector} in \(\RR^{n}\). 
	 
	In general, the task is to design suitable pair of encoder and estimation- and control-unit. The question of which pairs are deemed \emph{suitable} 
	depends first and foremoste on the specific objective regarding estimation and control, the behavior of the dynamic system as characterized by the matrix \(\mA\), 
	and the quantitative ability of the communication channel to transmit inforamtion. The latter is is expressed in terms of \emph{channel capacities}, the 
	relevant of which are the \emph{Shannon capacity} \cite{Sh48}, the \emph{zero-error capacity} \cite{Sh56} and the \emph{feedback zero-error capacity} \cite{Sh56}, 
	\begin{align*} C_{\text{Sh}}, C_{0}, C_{\text{Fb}}:~ \W(\X,\Y) \rightarrow \RR_{\hspace{1pt}}^{+},
	\end{align*}
	where \(\W(\X,\Y)\) is the set of conditional probability mass functions on finite alphabets \(\X\) and \(\Y\),
	\begin{align*}	\W(\X,\Y)	:=	\bigg\{ W: 	&~\X \times \Y \rightarrow\RR_{\hspace{1pt}0}^+,~ (x,y) \mapsto W(y|x),\\
												&~\forall x\in\X: ~{\sum}_{y\in\Y} W(y|x) = 1 \bigg\}.
	\end{align*}
	For a comprehensive introduction to different measures of information and their properties, we refer to \cite{CsKo11}.  
	As we will explain in the course of this section, the objective regarding estimation and control fully determines 
	which capacity has to be employed as a quantification of channel quality.
	
	The amount of data that needs to be transmitted depends exclusively on the characteristics of the dynamic system. 
	For \(\mA \in \RR^{n\times n}\), denote \(\bm{\lambda}(\mA) := (\lambda_1(A),\lambda_2(A),\ldots,\lambda_n(\mA))\) a family 
	consisting of all eigenvalues of \(\mA\), according to their algebraic multiplicity. Consequently, the family \(\bm{\lambda}(\mA)\)
	consists of exactly \(n\) components for all \(\mA\in \RR^{n\times n}\). We define
	\begin{align}	\eta(\mA):={\sum}_{j:|\lambda_j(\mA)|\geq 1} \log_2|\lambda_j(\mA)|.
	\end{align}
	Informally, the quantity \(\eta(\mA)\) equals the average number of bits that need to be transmitted per time instance in order
	to sucessfully estimate and control the state sequence \(\rss\).
	
	It remains to provide a formal objective regarding the estimation and control of the system's state sequence. The following variants were considered
	in \cite{MS07, MS07SC}. Each has been shown to involve one of the abovementioned capacities.
	
	1 - \(C_{\text{Sh}}\): \emph{State Estimation for Undisturbed Plants.} The scenario is characterized by the assumtion of a fully deterministic 
	state evolution, aside from the initial state being choosen at random. In other words, the sequence of noise-like fluctuations affecting the system satisfies
	\(\rz_t = \bm{0}\) for all \(t\in\NN\). The task is to design a pair \((\E,\De)\)
	(with \(\Dc\) satisfying \eqref{eq:No_Ctrl_Loop}) such that \(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| = 0\) holds true with probability \(p > \delta\).
	If \(\eta(\mA) < C_{\text{Sh}}\) is satisfied, there exists, for all \(0 \leq \delta < 1\), a pair \((\E,\De)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{\text{Sh}}\) is satisfied, there exists \(0 < \delta \leq 1\) such that for all possible pairs \((\E,\De)\), we have 
	\(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| = \infty\) with probability \(p > \delta\).	
		
	2 - \(C_{\text{Sh}}\): \emph{Stabilization for Undisturbed Plants.} The scenario is analogous to state estimation for undisturbed plants. 
	The task is to design a pair \((\E,\Dc)\) such that \(\limsup_{t\in\NN} \|\rs_t\| = 0\) holds true with probability \(p > \delta\).
	If \(\eta(\mA) < C_{\text{Sh}}\) is satisfied, there exists, for all \(0 \leq \delta < 1\), a pair \((\E,\Dc)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{\text{Sh}}\) is satisfied, there exists \(0 < \delta \leq 1\) such that for all possible pairs \((\E,\Dc)\), we have 
	\(\limsup_{t\in\NN} \|\rs_t\| = \infty\) with probability \(p > \delta\).
	
	3 - \(C_{0}\): \emph{State Estimation for Disturbed Plants.} The task is to design a pair \((\E,\De)\)
	(with \(\Dc\) satisfying \eqref{eq:No_Ctrl_Loop}) such that \(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| < \infty\) holds true almost surely.
	The the sequence of noise-like fluctuations may be bounded arbitrarily close to zero.
	If \(\eta(\mA) < C_{0}\) is satisfied, there exists a pair \((\E,\De)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{0}\) is satisfied, then \(\limsup_{t\in\NN} \|\rsh_t -\rs_t\| = \infty\) holds true almost surely for all possible pairs \((\E,\De)\).
	
	4 - \(C_{\text{Fb}}\): \emph{Stabilization for Disturbed Plants.} The scenario is analogous to state estimation for disturbed plants. The task is to design a pair \((\E,\Dc)\)
	such that \(\limsup_{t\in\NN} \|\rs_t\| < \infty\) holds true almost surely. The the sequence of noise-like fluctuations may be bounded arbitrarily close to zero.
	If \(\eta(\mA) < C_{\text{Fb}}\) is satisfied, there exists a pair \((\E,\Dc)\) that meets the requirement. On the other hand,
	if \(\eta(\mA) > C_{\text{Fb}}\) is satisfied, then \(\limsup_{t\in\NN} \|\rs_t\| = \infty\) holds true almost surely for all possible pairs \((\E,\Dc)\).
	
	In the following, we use the star symbol '\(\star\)' as a placeholder. In light of the results established in \cite{MS07, MS07SC}, we define 
	the sets 
	\begin{align}	\S_\star(\mA) :&= \big\{ W \in \W(\X,\Y) : C_\star > \eta(\mA)\big\}, \\
					\U_\star(\mA) :&= \big\{ W \in \W(\X,\Y) : C_\star < \eta(\mA)\big\},
	\end{align}
	for \(\star \in \{\text{'Sh'},\text{'\(0\)'},\text{'Fb'}\}\) and \(\mA\in\RR^{n\times n}\).
	
	\begin{Remark}	Further variants of the remote state estimation and control problem that were also considered in \cite{MS07, MS07SC} 
					allow communication channels with feedback. However, this supplementary degree of freedom does not introduce an additional channel capacity. 
	\end{Remark} 

\section{Preliminaries from the Theory of Turing Machines and Effective Analysis}\label{sec:introTuring}
	
	\noindent {\color{red} Copied from \cite{BoBoDe21TAC}!}
	
	\noindent In order to formalize the idea of algorithmic decidability, we employ the theory of Turing machines and, subsequently, 
	the theory of effective analysis, which is based on the former.	Turing machines were introduced in \cite{T37a,T38} in order to formalize the idea of computability. 
	The framework of Turing machines fully captures the theoretical limits of today's real-world digital computers. For \(n\in\NN\), a partial mapping \(f : \NN^n \part \NN\) 
	is referred to as recursive if and only if it can be computed on a Turing machine \cite{Kl36,T37b}. Hence, a function \(f :\NN^n \part \NN\) can, in principle, be 
	computed on a real-world digital computer if and only if it is recursive. 
	
	In the context of Turing machines, the partiality of recursive functions has a dedicated interpretation: for some partial recursive function \(f: \NN \part \NN\), 
	a number \(n\in\NN\) satisfies \(n\in D(f)\) if and only if the correspondig Turing machine \(\TM_f\) \emph{halts} and returns the value \(f(n)\) after a finite
	number of computing steps, whenever it receives the number \(n\) as input. In contrast, if \(n\) satisfies \(n\in \NN\setminus D(f)\), the Turing machine continues
	its computation forever, without ever reaching its halting state. 

	Applying the theory of Turing machines to the domain of real- and complex-valued analysis, we arrive at the 
	discipline of effective analysis. The latter will be the core ingredient in our investigation of the RSE problem. 
	For a comprehensive treatment of the topic, we refer to \cite{PoRi17,AB14}.%\FormatExtra{}{\pagebreak}

	\begin{Definition}  \label{ber}
						A sequence of rational numbers \((r_n)_{n\in\NN}\) is called computable if there exist recursive functions \(a,b,s:\NN\to\NN\), such that
						\begin{align*}   r_{n} = (-1)^{s(n)}\frac{a(n)}{b(n)} 
						\end{align*} 
						holds true for all \(n\in\NN\).
	\end{Definition}

	\begin{Definition}  \label{compreal}
						A number \(x\in\RR\) is called computable if there exists a computable sequence of rational numbers 
						\(\mathfrak{r} = (r_n)_{n\in\NN}\) such that \(|x-r_n|<2^{-n}\) holds true for all \(n\in\NN\). We denote the set of computable real numbers by \(\RRc\).
	\end{Definition}

	\begin{Remark}  A number \(x\in\RRc\) is computable if and only if there is a computable sequence \((r_n)_{n\in\NN}\) 
					of rational numbers and a recursive function \(\xi:\NN\to\NN\), such that \(|x-r_n|< 2^{-N}\)
					holds true for all \(n,N\in\NN\) that satisfy \(n \geq \xi(N)\). 
	\end{Remark}

	\noindent A computable sequence \(\mathfrak{r} = (r_n)_{n\in\NN}\) of rational numbers that satisfies \(|x-r_n|<2^{-n}\) for some number \(x\in\RRc\) 
	is referred to as a standard description of the number \(x\), which we denote by \(\mathfrak{r}\sim x\) in formal expressions. 
	
	\begin{Definition}	A sequence \((x_n)_{n\in\NN}\) of computable numbers is called computable if there exists a computable double-sequence
						\((r_{n,m})_{n,m\in\NN}\) of rational numbers such that 
						\begin{align} (r_{n,m})_{m\in\NN} =: \mathfrak{r}_n \sim x_n
						\end{align}
						holds true for all \(n\in\NN\).
	\end{Definition}
	
	In analogy to standard descriptions of computable numbers, the sequence \((\mathfrak{r}_n)_{n\in\NN}\) is referred to as a standard description
	of the sequence \((x_n)_{n\in\NN}\).

	Computable numbers can alternatively be characterized by computable sequences of rational numbers that satisfy monotonicity conditions. 
	In particular, there exists a Turing machine \(\TM_{\mathrm{std}\rightarrow\mathrm{alt}}\) that returns a pair \((\vec{\mathfrak{r}}, \cev{\mathfrak{r}})\) 
	whenever it receives a standard description \(\mathfrak{r}\) of some number \(x\in\RRc\) as input, such that
	\(	\vec{r}_n \leq \vec{r}_{n+1} \leq x \leq \cev{r}_{n+1} \leq \cev{r}_n
	\)
	as well as 
	\(	| \cev{r}_n - \vec{r}_n\hspace{1pt}| < 2^{-n}
	\)
	are satisfied for all \(n\in\NN\). Likewise, there exists a Turing machine \(\TM_{\mathrm{alt}\rightarrow\mathrm{std}}\) that returns a standard description 
	\(\mathfrak{r}\) of that number whenever it receives an alternative description \((\vec{\mathfrak{r}}, \cev{\mathfrak{r}})\) in the above sense as input. 
	For a more in-depth discussion, we again refer to \cite{PoRi17}. %\marker{\(\leftarrow\) Check This}

	The definition of computable numbers allows for the extension of the theory of computability to the realm of functions on the real numbers, 
	leading to the discipline of computable analysis. There are different approaches towards a formalization of computability on the reals; for a comparison 
	we refer to \cite{AB14}. We introduce the notions of \emph{Banach-Mazur} and \emph{Markov computability}, which is suitable for our purposes. 

	\begin{Definition}  \label{Borel}
						A function \(f : \RRc \to \RRc\) is called Banach-Mazur computable %\marker{\(\leftarrow\) Check This} 
						if for every computable sequence \((x_n)_{n\in\NN}\) of computable numbers, the sequence
						\((f(x_n))_{n\in\NN}\) is in turn a computable sequence of computable numbers.
	\end{Definition}
	
	\begin{Definition}  \label{Borel}
						A function \(f : \RRc \to \RRc\) is called Markov computable %\marker{\(\leftarrow\) Check This} 
						if there exists a Turing machine \(\TM_f\) that returns a standard description
						of the number \(f(x) \in \RRc\) whenever it receives a standard description of the number \(x\in \RRc\) as input.
	\end{Definition}
	
	\begin{Lemma}	Let \(f : \RRc \to \RRc\) be Markov computable. Then, \(f\) is Banach-Mazur computable.	
	\end{Lemma}\begin{proof}
					See \cite{AB14}.
	\end{proof}

	\noindent Since real-valued vectors and matrices are essentially multi-dimensional tuples of real numbers, the ideas of standard descriptions, computable sequences,
	Banach-Mazur computability and Markov computability naturally extend to the set \(\RRcP{n\times m} := (\RRc)^{n\times m}\) and vector/matrix-valued functions thereon. 
	{\color{red} Last but not least, we introduce a formal notion of decidability in the realm of computable \(n\times m\) - matrices \(\RRcP{n\times m}\):}

	{\color{red}\begin{Definition}  
						A set \(\A \subseteq \RRcP{n\times m}\) is called \emph{semi-decidable} as a subset of \(\RRcP{n\times m}\) 
						if there exists a Turing machine \(\TM_{\A}\) that reaches its halting state (and returns the value ``\(\mathtt{TRUE}\)") 
						after a finite number of computation steps if and only if it receives a standard description \(\mathfrak{A}\) of an element 
						\(\mA \in \RRcP{n\times m}\) that satisfies \(\mA\in\A\) as input. A set \(\A \subseteq \RRcP{n\times m}\) is called 
						\emph{decidable} as a subset of \(\RRcP{n\times m}\) if both \(\A\) and \(\overline{\A} := \RRcP{n\times m}\setminus\A\) are semi-decidable.
	\end{Definition}} 
	
	\begin{Definition}  \label{semi}
						A set \(\A \subseteq \RRcP{n\times m}\) is called \emph{semi-decidable} as a subset of \(\RRcP{n\times m}\) 
						if there exists a Turing machine \(\TM_{\A}\) that reaches its halting state (and returns the value ``\(\mathtt{TRUE}\)") 
						after a finite number of computation steps if and only if it receives a standard description \(\mathfrak{A}\) of an element 
						\(\mA \in \RRcP{n\times m}\) that satisfies \(\mA\in\A\) as input. A set \(\A \subseteq \RRcP{n\times m}\) is called 
						\emph{decidable} as a subset of \(\RRcP{n\times m}\) if both \(\A\) and \(\overline{\A} := \RRcP{n\times m}\setminus\A\) are semi-decidable.
	\end{Definition} 
	
	\noindent The Turing machine \(\TM_\A\) is said to \emph{accept} standard descriptions \(\mathfrak{A}\) of elements \(\mA\in\A\).
	
	{\color{red} 
	\begin{Remark} Decidability and Recursiveness, indicator function\end{Remark}}
	
	{\color{red} Decidability \emph{relative} to some set... Consistency in nomenclature between versions?}
	
\section{Turing Computability and Channels (Working Title)}
	\begin{Lemma}	\label{lem:IndicatorFunctionBanachMazur}
					Let \(\X,\Y\) be finite Alphabets and \(\M_0, \M_1\) disjoint subsets of \(\Wc(\X,\Y)\) that satisfy the following:
					\begin{itemize}	\item There exist \(W_0\in\M_0\) and \(W_1\in\M_1\) such that for all \(\mu \in (0,1]\cap \RRc\), 													
										we have \((1-\mu)W_0 + \mu W_1 \in \M_1\). 
					\end{itemize}
					Then, the indicator-function \(\mathds{1}_{\M_0} : \M_0\cup \M_1 \rightarrow \RRc\) is \emph{not} Banach-Mazur computable.
	\end{Lemma}\begin{proof}
					We prove the claim by contradiction. Thus, assume the function \(\mathds{1}_{\M_0}\) is Banach-Mazur computable. Let 
					\(\N\subset \NN\) be a recursively enumerable, nonrecursive set and consider a recursive enumeration \(f_\N : \NN \rightarrow \N\)
					of \(\N\). For all \(n,m\in\NN\), define
					\begin{align}	g(n,m) := 	\begin{cases}	0 &\text{if~} n \in \big\{f_\N(l) : 1 \leq l \leq m\big\}, \\ 	
																1 &\text{otherwise}.
												\end{cases}
					\end{align}
					Then, \(g: \NN^2 \rightarrow \NN\) is a total recursive function that satisfies the following:
					\begin{itemize}	\item 	for all \(n,m,l\in\NN\) that satisfy \(m\leq l\), we have \linebreak \(g(n,m) = 0 \Rightarrow g(n,l) = 0\);
									\item	for all \(n\in\NN\), there exists \(m\in\NN\) such that \(g(n,m) = 0\) is satisfied if and only if 
											\(n\in \N\) holds true.
					\end{itemize}
					Next, define the computable double sequence \((r_{n,m})_{n,m\in\NN}\) of rational numbers via
					\begin{align}	r_{n,m} := 1 - \sum_{l = 1}^{m+1} g(n,l)\cdot 2^{-l}
					\end{align}
					for all \(n,m\in\NN\). Then, the sequence \((r_{n,m})_{n,m\in\NN}\) satisfies the following:
					\begin{itemize}	\item	we have \(\lim_{m\to\infty} r_{n,m} =: x_n \in [0,1]\) for all \(n\in \NN\);
									\item	for all \(n,m,l\in\NN\) with \(m < l\), we have either \(r_{n,m} < 2^{-m}\) or   
											\(r_{n,m} = r_{n,l}\). Hence, we have \(|x_n - r_{n,m}| < 2^{-m}\) for all \(n,m\in\NN\),
											making \((x_n)_{n\in\NN}\) a computable sequence of computable numbers with 
											\((r_{n,m})_{n,m\in\NN} \sim (\mathfrak{r}_{n})_{n\in\NN} \sim (x_n)_{n\in\NN}\);
									\item 	we have \(x_n = 0\) if and only if \(n\in\N\) is satisfied. 
					\end{itemize}   
					Now consider channels \(W_0\in\M_0\) and \(W_1\in\M_1\) as specified by the claim. Define the sequence \((V_n)_{n\in\NN}\) via
					\begin{align}	(1-x_n)W_0 + x_n W_1 =: V_n \in \Wc(\X,\Y).
					\end{align}
					Since multiplication and addition are Markov computable on \(\RRc\), the sequence \((V_n)_{n\in\NN}\) is a computable
					sequence of computable channels. Furthermore, for all \(n\in\NN\), we have \(V_n \in \M_0\) if and only if \(n\in\N\) holds true. 
					By assumption, the indicator function \(\mathds{1}_{\M_0}\) is Banach-Mazur computable. Hence, there exists a computable sequence
					\((\xp{n})_{n\in\NN}\) of computable numbers that satisfies
					\begin{align}	\xp{n}	&= 	\begin{cases}	1	&\text{if}~ V_n \in \M_0, \\
																0 	&\text{otherwise},
												\end{cases} \\
											&=	\begin{cases}	1	&\text{if}~ n \in \N, \\
																0 	&\text{otherwise}.
												\end{cases} 
					\end{align}
					Let \((\rp{n,m})_{n,m\in\NN}\) be a standard description of \((\xp{n})_{n\in\NN}\). Then, for all \(n\in\NN\), we have
					\begin{align}	\rp{n,1} 	\begin{cases}	> 2^{-1}	&\text{if}~ n \in \M_0, \\
																< 2^{-1} 	&\text{otherwise}.
												\end{cases} 
					\end{align}
					Hence, for the indicator function \(\mathds{1}_\N\) of \(\N\), we obtain
					\begin{align}	\mathds{1}_\N =		\begin{cases}	1	&\text{if}~\rp{n,1} > 2^{-1}, \\
																		0	&\text{otherwise}.
														\end{cases} 
					\end{align}
					Since \(\rp{n,1}\) is a rational number for all \(n\in\NN\), the predicate \(P(n) \equiv  \rp{n,1} > 2^{-1}\) can be
					evaluated effectively for all \(n\in\NN\), making \(\mathds{1}_\N\) a recursive function, which is a contradiction to the nonrecursivity of \(\N\).			
	\end{proof}
	\begin{Lemma}	\label{lem:SubsetNotSemidecidable}
					Let \(\X,\Y\) be finite Alphabets and \(\M_0, \M_1\) disjoint subsets of \(\Wc(\X,\Y)\) that satisfy the following:
					\begin{itemize}	\item There exist \(W_0\in\M_0\) and \(W_1\in\M_1\) such that for all \(\mu \in (0,1]\cap \RRc\), 													
										we have \((1-\mu)W_0 + \mu W_1 \in \M_1\). 
					\end{itemize}
					Then, the sets \(\M_0\) and \(\M_1\) are \emph{not} decidable as subsets of \(\M_0 \cup \M_1\). In particular, the set 
					\(\M_0\) is \emph{not} semi-decidable as subset of \(\M_0 \cup \M_1\).
	\end{Lemma}\begin{proof}
					We prove the claim by contradiction. Thus, assume the set \(\M_0\) is decidable as subset of \(\M_0 \cup \M_1\). 
					Then, there exists a Turing machine \(\TM_0\) that returns the value ``\(\mathtt{TRUE}\)" whenever it receives a standard description
					\(\mathfrak{W}\) of some channel \(W\in \M_0\) as input, and does \emph{not} halt otherwise. Observe that the mapping
					\begin{align}	\mu \mapsto W(\mu) := (1-\mu)W_0 + \mu W_1
					\end{align} 
					is Markov computable, since it constist exclusively of component-wise addidtions and multiplications, which in turn are Markov computable on \(\RR_c\).
					In other words, there exists a Turing machine \(\TM_{\mu\mapsto W}\) that returns a standard descritption \(\mathfrak{W}\) of 
					\(W(\mu)\) whenever it receives a standard description \(\mathfrak{m}\) of \(\mu\) as input. We have \(W(\mu) \in \M_0\) if and only if
					\(\mu = 0\) is satisfied. Thus, by concatenation, we obtain a Turing machine
					\(\TM_{=0}\) that satisfies
					\begin{align}	\mathfrak{m} \sim \mu \wedge \mu = 0	\quad\Leftrightarrow\quad  \TM_{=0}(\mathfrak{m}) = \mathtt{TRUE},
					\end{align}
					which is a contradiction to the undecidability of the \emph{halting} problem, see \sdummy.
	\end{proof}
	
\section{Discussion on Banach-Mazur Computability (Working Title)}
	In the scope of system verification, Banach-Mazur computability has a noteworthy interpretation.
	For reasons of expedience, we will discuss this interpretation in the context of remote system control; the underlying principle can be 
	directly transferred to problems that are similar in structure.
	
	Consider a setup similar to the one depicted in Figure \ref{fig:Schematics}. An unstable, dynamic system is to be stabilized remotely via a control link.
	The remote controller observes the system via a DMC \(W\), which belongs to one of two disjoint sets \(\M_0\) and \(\M_0\). For example, the set \(\M_0\) may
	correspont to the set of \emph{critical} channels, that are insufficient for the remote stabilization of the system. In order to control the system automatically,
	an autonomous control tool is designed, which is required to initiate special actions if it detects the communication link to belong to the set \(\M_0\). For example,
	it might increase the transmission power to increase the quality of the channel, or, in extreme cases, shut down the system. For the sake of the argument, we
	do not require the autonomous control tool to meet any constraints regarding computability; rather, we think of it as a black-box that implements an arbitrary
	(but fixed) function that maps a set \(\M_0\cup \M_1\) to \(\{0,1\}\).
	
	Before such an autonomous control tool is put into operation, it is likely required to undergo a series of test to provide evidence for its functionality.
	A possible test bench is visualized in Figure \ref{fig:Verification}: the tool is fed with a series of automatically generated, artificial inputs 
	\begin{align}	V_1,V_2,V_3,\ldots \in (\M_0\cup \M_0) \cap \Wc(\X,\Y), 
	\end{align}
	while the tool's output is compared to a target value by a verifier. 
	\begin{figure}\linespread{1}
		\centering
		\begin{tikzpicture}[scale = 0.7, every node/.style={scale=0.7}]
			%   %   %   %   %   %   %   %   %   %   %
			%   Input Generator
				\fill[fill=black!15, rounded corners=0.1cm] (-5,2) rectangle (-3,0);
				\draw (-4, 1)  node[anchor=center] {\((V_n)_{n\in\NN} \vphantom{\Bigg|}\)};
				\draw (-4,2)  node[anchor=south] {Input Generator};
			%   %   %   %   %   %   %   %   %   %   %
			%   Autonomous Decision-Maker
				\draw[thick, fill=black!25] (-1,2) rectangle (1,0);
				\draw (0, 1)  node[anchor=center] {\(V_n \overset{\hspace{2pt}?}{\in} \M_0 \vphantom{\Bigg|}\)};
				\draw (0,2)  node[anchor=south, align = center] {Autonomous\\ Decision-Maker};
			%   %   %   %   %   %   %   %   %   %   %
			%   Verifier
				\fill[fill=black!15, rounded corners=0.1cm] (3,2) rectangle (5,0);
				\draw (4, 1)  node[anchor=center] {\(\overset{?}{=}\substack{\text{Target}\\\text{Value}}\vphantom{\Bigg|}\)};
				\draw (4,2)  node[anchor=south] {Verifier};
			%   %   %   %   %   %   %   %   %   %   %
			%   Test Cases
				\draw[very thick, ->, shorten >=1.5pt] (-0.1,-1.2) -- (-0.1,-0.7) -- (-4,-0.7) -- (-4,0); 
				\draw[very thick, ->, shorten >=1.5pt] (0.1,-1.2) -- (0.1,-0.7) -- (4,-0.7) -- (4,0);
				\draw (0,-1.2)  node[anchor=north]
				{\(n= 1,2,3,\ldots\)};
				\draw (0, -0.7)  node[anchor=south]
				{Test Cases};
			%   %   %   %   %   %   %   %   %   %   %
			%   Input Generator -> Autonomous Decision-Maker
				\draw[very thick, ->, shorten >=1.5pt] (-3,1) -- (-1,1.); 
				\draw (-2,1)  node[fill = white, anchor=center]
				{\(V_n\)};
			%   %   %   %   %   %   %   %   %   %   %
			%   Autonomous Decision-Maker -> Verifier
				\draw[very thick, ->, shorten >=1.5pt] (1,1) -- (3,1.); 
				\fill[fill = white] (1.6,1.5) rectangle (2.4, 0.5);
				\draw (1.7,1) -- (2.3,1); 
				\draw (2,1)  node[anchor=south]
				{\(\mathtt{YES}\)};
				\draw (2,1)  node[anchor=north]
				{\(\mathtt{NO}\)};				
		\end{tikzpicture}
		\caption{Interpretation of Banach-Mazur computability in the context of (semi-automated) system verification.}
		\label{fig:Verification}
	\end{figure}
	
	Provided that the sequence of test cases \((V_n)_{n\in\NN}\) is digitally generated and the indicator function \(\mathds{1}_{\M_0}\) is Banach-Mazur computable, 
	it is always possible to implement a digital verifier that generates the sequence 
	\begin{align} 	\mathds{1}_{\M_0}(V_1), \mathds{1}_{\M_0}(V_2), \mathds{1}_{\M_0}(V_3),\ldots	\in \{0,1\} 
	\end{align}
	of \emph{correct} target values,
	which can then be compared to the autonomous control tool's output. Unless the indicator function \(\mathds{1}_{\M_0}\) is Turing computable, an individual verifier has to be implemente for each 
	possible sequence of test cases. If, on the other hand, the indicator function \(\mathds{1}_{\M_0}\) is not Banach-Mazur computable, it is not generally possible to generate the 
	sequence of correct target values on digital hardware. In other words, for some sequences \((V_n)_{n\in\NN}\), there may not exist a digital verifier at all in this case.

\section{Preliminaries from the Theory of Blum-Shub-Smale Machines}	\label{sec:PreliminariesBSS}	    	
	\noindent Blum-Shub-Smale (BSS) machines formalize the notion of computability over a field \(\FF\). The latter is assume to be equipped 
	with a binary relation \(\diamond~{:}~\FF \times \FF \rightarrow \{\mathsf{T},\mathsf{F}\}\), which is either an equality, equivalence or strict total order. 
	
	Despite the so called Church-Turing thesis being widely accepted as true, which implies that the capabilities of real-world computers are exactly characterized 
	by the abstract Turing machine, BSS machines are often implicitly considered as the underlying machine model in numerics and complexity theory \tbr{\sdummy}. 
	A reason for this practice may lie in the ability of BSS machines to handle exact real numbers. Since most areas of applied mathematics involve continuous structures, 
	treating the content of a computer's memory as actual real numbers simplifies the description of algorithms to a great extent. For a detailed discussion on the Topic, we refer to \cite{Bl04}.

	In essence, BSS machines can be considered a generalization of Turing machines. They are equipped with a two-way infinite tape divided into cells, each of which holds an 
	element of \(\FF\cup\{\sqcup\}\). Here, "\(\sqcup\)" denotes the distinguished empty-space symbol. We assume that the tape is almost empty, i.e., all but finitely many cells 
	contain the symbol "\(\sqcup\)", at the beginning of the computation. A BSS machine interacts with its tape by means of a read-write head, which can, depending on tis current 
	position, access a fixed number of contiguous cells at a time. The algorithm executed by the BSS machine is characterized by its program, a finite, directed, simple graph 
	\begin{align*}   \G_\BSS = ([M_\BSS]_{0}, \V_\BSS),~ \V_\BSS \subseteq [M_\BSS]_{0} \times [M_\BSS],
	\end{align*} 
	with five types of nodes: \emph{input nodes}, \emph{computation nodes}, \emph{branching nodes}, \emph{shifting nodes} and \emph{output nodes}, each of which specifies a class 
	of fundamental machine operations. For a given input, the program flow corresponds to a directed walk in the program graph
	\begin{align*}	\F := (e_t)_{t\in\{1,2,\ldots,T\}},~T\in\NN\cup \{\infty\},
	\end{align*}
	starting from the input node and (possibly) ending in some output node, or continuing infinitely. In each step, the operation associated to the current node is executed, 
	affecting the content of the tape, the position of the read-write head and the program flow accordingly. Furthermore, the values stored in the initially non-empty cells 
	of the tape are considered part of the algorithm, much like hard-coded constants in a real-world computer program. 

	In order to prove that some problem is BSS-computable, on has, in principle, to provide the existence of a suitable program graph and, possibly, a tape with predefined constants. 
	This can often be cumbersome, since it involves the exact specification of the movement of the read-write head. If the size of the \emph{memory} required to execute the program, i.e., 
	the number of different cells accessed throughout the program execution, can be uniformly upper bounded by a number \(J_\BSS \in \NN\), we can get rid of the tape altogether by 
	introducing \emph{register variables} and \emph{constants},
	\begin{align*}	\bm{r} :&= (r_j^t)_{j\in\{1,\ldots,J_{\mathrm{R}}\}, t\in\{1,\ldots,T\}},\\
					\bm{c} :&= (c_j)_{j\in\{J_{\mathrm{R}} + 1,\ldots,J_{\mathrm{C}}\}},
	\end{align*}
	with \(T\in\NN\cup\{\infty\}\) and \(J_{\mathrm{C}} \leq J_\BSS\). The program graph then consists only of an input node, computation nodes, branching nodes and at least one output node.
	Furthermore, the corresponding classes of fundamental machine operations can be specified as follows:
	
	1 - \emph{Input nodes.} The unique input node \(\iota = e_1 = 0\) is associated to an 
		input operation \(g_\iota\). The input operation writes each component of a tuple 
		\begin{align*} 	\bm{a} = \big(a_1,a_2,\ldots a_{K({\bm{a}})}\big) \in {\bigcup}_{j=1}^{J_{\mathrm{R}}} \FF^{j}
		\end{align*}
		to the machine's internal registers \(\bm{r}\), according to the specification
		\begin{align*}	r^1_{j(k)} := a_k ,~ j(k)\in \{1,\ldots,J_{\mathrm{R}}\},~ k\in \{1,\ldots K(\bm{x})\}.   
		\end{align*}
		The remaining registers are initialized with the value\linebreak \(0 \in \FF\).
		There exists a unique next node \(\iota' \in [M_\BSS]\) to \(\iota\).
	
	2 - \emph{Computation nodes.} The program graph may contain a number of computation nodes \(\zeta \in \{1,2,\ldots M_{\mathrm{C}}\}\),    
		\linebreak \(M_{\mathrm{C}} \leq M_{\BSS}\), each of which is 
		is associated to a mapping 
		\( 	g_\zeta : \FF^{J_{\mathrm{C}}}\rightarrow \FF^{J_{\mathrm{R}}}, 
		\) 
		which is either polynomial, rational or has previously been shown to be BSS computable. The latter accounts for the fact that in the general, 
		unbounded setting, the program of some BSS machine can always be incorporated as a subroutine into the program of another BSS machine.
		If \(e_t = \zeta\) for some \(t\in\{1,\ldots, T-1\}\), we have
		\begin{align*}  \bm{r}^{t+1} = g_{\zeta}(\bm{r}^t,\bm{c})~\text{with}~\bm{r}^t := (r_j^t)_{j\in\{1,\ldots,J_{\mathrm{R}}\}}.
		\end{align*}
		There exists a unique next node \(\zeta' \in \{1,2,\ldots M_{\mathrm{C}}\}\) to each computation node \(\zeta\).
	
	3 - \emph{Branching nodes.}  A program may contain a number of branching nodes \(\beta \in \{M_{\mathrm{C}} + 1, M_{\mathrm{C}} + 2,\ldots, M_\mathrm{B}\}\), 
		each of which leave the content of the internal registers unchanged. That is, if \(e_t = \beta\) for some \(t\in\{1,\ldots, T-1\}\), we have
		\(\bm{r}^{t+1} = \bm{r}^{t}\). There exist exactly two next nodes \(\beta'(\mathsf{T})\) and \(\beta'(\mathsf{F})\) to each branching node \(\beta\). If 
		\(	\diamond\big(0, r^t_{j'(\beta)}\big) = \mathsf{T} 
		\)
		holds true for \(j'(\beta) \in \{1,\ldots, J_\mathrm{R}\}\), the program flow branches to the node \(\beta'(\mathsf{T})\). Otherwise, it moves to \(\beta'(\mathsf{F})\). 
		That is, for \(\beta = e_t\), we have
		\begin{align*}   e_{t+1} =   \begin{cases}   \beta'(\mathsf{T})  &\text{if}~\diamond\big(0,r^t_{j'(\beta)}\big) = \mathsf{T},\\
													\beta'(\mathsf{F})  &\text{otherwise}.
									\end{cases}    
		\end{align*}
		
	4 - \emph{Output nodes.} Each program contains at least one output node \(\sigma \in \{M_{\mathrm{B}} + 1, M_{\mathrm{B}} + 2,\ldots, M_\BSS\}\), 
		each of which is associated to an output mapping
		\(	o_\sigma : \FF^{J_{\mathrm{C}}}\rightarrow \FF^{J_{\sigma}}.
		\)
		For some fixed subset \(\J_\sigma\) of \([J_\mathrm{C}]\) and \(e_t = e_T = \sigma\), \(T\in\NN\), the mapping outputs (by projection) the values of the 
		register variables \((r_j^T)_{j\in \J_\sigma \cap \{1,\ldots,J_\mathrm{R}\}}\) and constants \((c_j)_{j\in \J_\sigma \cap \{J_\mathrm{R}+1,\ldots,J_\mathrm{C}\}}\). 
		There exists no next node to \(\sigma\).

	In our case, the field \(\FF\) will be the real numbers \(\RR\) with the usual strict total order "\(<\)". If \(\FF\) equals \(\ZZ_2\) (the set of boolean values with logical con- and disjunction 
	as field operations), the traditional theory of computation as formalized by Turing machines is recovered. For the remainder of this article, we will refer to BSS machines over \(\RR\) 
	simply as BSS machines, omitting the explicit mention of the field \(\FF\) being equal to the real numbers. 

%\section{Preliminaries from the Theory of Zero-Error Coding}	\label{sec:PreliminariesZeroError}
	%\noindent As indicated in Section \ref{sec:FormalEstimationSetup}, we consider finite alphabets \(\X\) and \(\Y\) as well as conditional probability mass functions on \(\Y\times\X\).
	%In particular we define
	%\begin{align*}	\W(\X,\Y)	:=	\bigg\{ W: 	&~\X \times \Y \rightarrow\RR_{\hspace{1pt}0}^+,~ (x,y) \mapsto W(y|x),\\
												%&~\forall x\in\X: ~{\sum}_{y\in\Y} W(y|x) = 1 \bigg\}.
	%\end{align*}
	%The triple \((\X,\Y,W)\) is called a \emph{discrete, memoryless channel}. 

	%The theory of zero-error coding, as introduced in \cite{Sh56}, is a sub-discipline of general channel coding. In essence, it considers the problem of finding the supremum 
	%\(C_0(W)\) of all possible rates at which information can be transmitted trough a DMC \((\X,\Y,W)\) with perfect reliability. Here, ``perfect reliability'' refers
	%to the ability of the decoder to correctly infer the transmitted message with probability one. Furthermore, the term ``rate'' denominates the asymptotic average of bits transmitted per channel use. 
	%The number \(C_0(W)\) is commonly referred to as zero-error capacity of \(W\).

	%Given a DMC \((\X,\Y,W)\), one of the results derived in \cite{Sh56} yields a characterization of \(C_0(W)\) in graph-theoretic terms.
	%In fact, for each \(W\in \W(\X,\Y)\), there exists a finite, undirected, simple graph \(G(W)\), referred to as the \emph{confusability graph} of \(W\), which
	%uniquely determines \(C_0(W)\).

	%\begin{Theorem}	[\cite{Sh56}]\label{thm:ZE_Capacity}
					%For a DMC \(W\in\W(\X,\Y)\), let \(G(W) = (\X, \V(W))\) be the finite, simple graph that satisfies
					%\begin{align*}   \V(W) = \big\{\{x,x'\} : \exists y : W(y|x)W(y|x') > 0\big\}.
					%\end{align*}
					%Then, the zero-error capacity of \(W\) satisfies
					%\begin{align*}   C_0(W)  	&=  \lim_{n\to\infty} \frac{1}{n} \log_2 \alpha\big(G^{\boxtimes n }(W)\big) \\
												%&=  \sup_{n\in\NN} \frac{1}{n} \log_2 \alpha\big(G^{\boxtimes n }(W)\big),
					%\end{align*}
					%where \(G^{\boxtimes n }(W)\) denotes the \(n\)-fold \emph{strong graph product} of \(G(W)\) with itself and
					%\(\alpha\big(G^{\boxtimes n }(W)\big)\) denotes the \emph{independence number} of \(\alpha\big(G^{\boxtimes n }(W)\big)\).
	%\end{Theorem}
	
	%For finite alphabets \(\X,\Y\), we denote by \(\Wc(\X,\Y)\) the set of conditional probability mass functions \(W\) on \(\X\times\Y\) such that \(W(y|x) \in \RRc\) 
	%holds true for all \((x,y) \in \X\times \Y\). In \cite{BD20Z}, it was shown that \(C_0(W)\) is not computable on a Turing machine as a function on computable channel descriptions \(W\).
	%To the best of the author's knowledge, it remains an open problem whether \(C_0(W)\) is even a Turing computable number for all computable channel descriptions.
	%In Section \ref{sec:ComputingZeroErrorOnBSS}, we describe a BSS-algorithm that, for fixed alphabets \(\X\) and \(\Y\), computes \(C_0(W)\) as a function on \(\W(\X,\Y)\). The existence 
	%of such an algorithm essentially relies on the ability of BSS machines to handle exact real numbers.

\section{Computing the Zero-Error Capacity for Fixed Alphabets on Blum-Shub-Smale Machines}	\label{sec:ComputingZeroErrorOnBSS}
	\noindent In the following, we specify a BSS-Algorithm which, for fixed alphabets \(\X\) and \(\Y\), computes the zero-error capacity \(C_0(W)\) 
	upon being passed a channel description \(W \in \W(\X,\Y)\). 

	Essentially, the algorithm relies on the fact that a \emph{lookup table} containing all possible values of \(C_0(W)\) can be hard-coded into the program. The lookup is performed in 
	terms of a perfect binary tree, where each branch corresponds to an evaluation of the predicate "\(W(y|x) > 0\)" for some letters \(x\in\X\) and \(y\in\Y\). Per definition, the latter 
	can be done algorithmically, as a fundamental operation on the BSS machine.

	\begin{Theorem}	\label{thm:ZeroErrorBSScomputable}
					Consider finite alphabets \(\X\) and \(\Y\). Then, there exists a BSS-Machine \(\BSS_{C_0}\)
					which, upon being passed a channel description \(W\in \W(\X,\Y)\), computes the mapping \(W \mapsto C_0(W)\).
	\end{Theorem}\begin{proof}
					Let \(j \mapsto \big(x(j), y(j)\big)\) be an enumeration of the set \(\X\times\Y\) and define
					\(J_\mathrm{R} := |\X\times \Y|\). Furthermore, consider the mappings
					\begin{align*}	\delta(W,j) :&=     \begin{cases}   1   &\text{if}~ 0 < W\big(y(j)|x(j)\big), \\
																		0   &\text{otherwise},
														\end{cases}\\
									\Delta(W)   :&=     1 + {\sum}_{j=1}^{J_\mathrm{R}} \delta(W,j)\cdot 2^{j-1} \in \big\{1,\ldots,2^{J_\mathrm{R}}\big\}.
					\end{align*} 
					We observe that, as a direct consequence of Theorem \ref{thm:ZE_Capacity}, the value of \(C_0(W)\) is 
					entirely determined by the set 
					\begin{align*}   \{(x,y) \in \X\times \Y : W(x|y) > 0\} \subseteq \X\times\Y
					\end{align*} 
					and hence, the zero-error capacity of \(W\) depends exclusively on the number \(\Delta(W)\). Thus, we obtain the existence of a mapping
					\(C'_0 : \big\{1,\ldots,2^{J_\mathrm{R}}\big\} \rightarrow \RR_0^+,~ \Delta \mapsto C'_0(\Delta),        
					\)
					such that \(C'_0(\Delta(W)) = C_0(W)\) holds true for all \(W\in\W(\X,\Y)\). For \(J_\mathrm{C} := J_\mathrm{R} + 2^{J_\mathrm{R}}\), 
					hardcode the family of constants \(\bm{c}\) according to 
					\(  c_j := C'_0(j - J_\mathrm{R})
					\)
					for all \(j\in \{J_\mathrm{R} + 1, \ldots, J_\mathrm{C}\}\) and specify the program \(\G = ([M_\BSS],\V_\BSS)\) with
					\begin{align*}	M_\mathrm{C} := 0,~M_\mathrm{B} := 2^{J_\mathrm{R}} - 1,~ M_\BSS := ~M_\mathrm{B} + 2^{J_\mathrm{R}}
					\end{align*}
					in the following way:
					\begin{enumerate}	\item[\(\iota\)\hspace{1pt}:] Preallocate the machine's registers \(\bm{r} := \bm{r}^1\) according to
											\(r_j := r^1_j := W\big(y(j)|x(j)\big)\) and set \(\iota' := 1\). Since the program does not contain any computation nodes,
											the content of the registers remains constant during the execution. We thus omit the superscript of the
											register variables in the following.
										\item[\(\beta\)\hspace{1pt}:] 
											For \(\beta \in \{1,\ldots, M_\mathrm{B}\}\), the pair of next nodes \(\big(\beta'(\mathsf{T}),\beta'(\mathsf{F})\big)\) satisfies
											\(	\beta'(\mathsf{T}) :    =  2\beta + 1, \quad
												\beta'(\mathsf{F}) :    =  2\beta.
											\)
											Denote \(m\in\NN\) the smallest natural number such that \(\beta < 2^m\) is satisfied. If, for some \(t\in\{1,\ldots, T-1\}\), we have
											\(e_t = \beta\), then \(e_{t+1}\) satisfies
											\begin{align*}   e_{t+1} := \begin{cases}	\beta'(\mathsf{T}) &\text{if}~ 0 < r_m,\\
																						\beta'(\mathsf{F}) &\text{otherwise}.
																		\end{cases}
											\end{align*}
										\item[\(\sigma\)\hspace{1pt}:] For \(\sigma \in \{M_\mathrm{B} +1, M_\BSS\}\), set \(j(\sigma) := \sigma - M_\mathrm{B} + J_\mathrm{R}\) 
											and return \(c_{j(\sigma)}\).
					\end{enumerate}
					Then, the BSS machine \(\BSS_{C_0}\) characterized by the triple \((\bm{r}, \bm{c}, \G)\) computes the mapping \(W\mapsto C_0(W)\).
	\end{proof}
	
	\begin{Remark}
		Semi-algebraic sets!
	\end{Remark}

\section{Decidability Analysis}	\label{sec:DecidingRemoteStateEstimationOnBSS}
	In this section, we will use Theorem \ref{thm:ZeroErrorBSScomputable} to derive a BSS algorithm which, given the description of an unstable, linear plant,
	decides the solvability of the remote state estimation problem as a function on \(\W(\X,\Y)\).
	
	Again, the algorithm essentially relies on the ability of BSS machines to handle exact real numbers. 
	%For \(\mA \in \RR^{n\times n}\), denote \(\bm{\lambda}(\mA) := (\lambda_1(A),\lambda_2(A),\ldots,\lambda_n(\mA))\) a family 
	%consisting of all eigenvalues of \(\mA\), according to their algebraic multiplicity. Consequently, the family \(\bm{\lambda}(\mA)\)
	%consists of exactly \(n\) components for all \(\mA\in \RR^{n\times n}\). We define
	%\begin{align}	\eta(\mA):={\sum}_{j:|\lambda_j(\mA)|\geq 1} \log_2|\lambda_j(\mA)|.
	%\end{align}
	
	%As indicated in the introduction, the zero-error capacity of the DMC \(W\) plays a central role in the solvability of the remote state estimation problem;
	%in essence, given a characterization \((\mA,\mB,W,\E,\D)\) of a remote state estimation setup, it is almost entirely determined by the pair \((\eta(\mA),C_0(W))\).
	
	%\begin{Lemma} 	[\cite{MS07}]\label{lem:SolvabilityCondition} Let \(\X,\Y\) be finite alphabets, \(W\in \W(\X,\Y)\) a DMC and \((\mA,\mB) \in \RR^{n\times n}\times \RR^{m\times n}\) 
					%a characterization of an unstable, time-invariant, linear plant and an associated local sensor. Then, the following holds true:
					%\begin{itemize}	\item If \(\eta(\mA) < C_0(W)\) is satisfied, there exists an encoder/decoder-pair \((\E,\D)\) such that we have
										%\(
											%\sup_{t\in\NN} |\rs(t) - \hat{\rs}(t)| < \infty 
										%\) almost surely.
										%That is, the remote state estimation problem is \emph{solvable} for \((\mA,\mB, W)\).
									%\item If \(\eta(\mA) > C_0(W)\) is satisfied, then, for every encoder/decoder-pair \((\E,\D)\), we have\linebreak 
										%\(
											%\sup_{t\in\NN} |\rs(t) - \hat{\rs}(t)| = \infty 
										%\) almost surely.
										%That is, the remote state estimation problem is \emph{unsolvable} for \((\mA,\mB, W)\).
					%\end{itemize}
	%\end{Lemma} 
	
	%In view of the solvability conditions stated in Lemma \ref{lem:SolvabilityCondition}, we introduce the sets
	%\begin{align*}	\S_{\mA}(\X,\Y) := \left\{ W\in \W(\X,\Y) : \eta(\mA) < C_0(W) \right\} \\ 
					%\U_{\mA}(\X,\Y) := \left\{ W\in \W(\X,\Y) : \eta(\mA) > C_0(W) \right\} 
	%\end{align*}
	%Then, if \(W\in \S_{\mA}(\X,\Y)\) holds true, the remote state estimation problem is \emph{solvable} for \((\mA,\mB, W)\).
	%Likewise, if \(W\in \U_{\mA}(\X,\Y)\) holds true, the remote state estimation problem is \emph{unsolvable} for \((\mA,\mB, W)\).
	%In the following, denote \(\mathds{1}_{\S_{\mA}(\X,\Y)}\), \(\mathds{1}_{\U_{\mA}(\X,\Y)}\) the \emph{indicator function}
	%of \(\S_{\mA}(\X,\Y)\), \(\U_{\mA}(\X,\Y)\), respectively.
	\begin{Lemma} \label{lem:SstarSatisfiesProp}
		For \(\star \in \{\text{'\(0\)'},\text{'Fb'}\}\) and \(\mA\in\RRcP{n\times n}\) with \(\log_2\min\{|\X|,|\Y|\} > \eta(\mA) > 0\), there exists channels
		\(W_0 \in \S_\star(\mA)\cap \Wc(\X.\Y)\) and \(W_1\in \U_\star(\mA)\cap\Wc(\X,\Y)\), such that for all \(\mu\in (0,1]\cap\RRc\), 
		we have
		\begin{align}	(1-\mu)W_0 + \mu W_1 \in \U_\star(\mA)\cap\Wc(\X,\Y).
		\end{align}  
	\end{Lemma}\begin{proof}
		Observe that for \(W\in\W(\X,\Y)\) both the zero-error and the feedback zero-error capacity are entirely determined by the set
		\begin{align*}   \Omega(W) := \{(x,y) \in \X\times \Y : W(x|y) > 0\} \subseteq \X\times\Y.
		\end{align*}
		For details, see \cite{Sh56}. In particular, we have 
		\begin{align}	\Omega(W) = \X\times\Y \quad \Rightarrow \quad C_\star(W) = 0.
		\end{align}
		Furthermore, for all (nonempty) finite alphabets \(\X\) and \(\Y\), there exists a channel 
		\(\W_0\in \Wc(\X,\Y)\) that satisfies 
		\begin{align}	C_\star(W) = \log_2 \min \{|\X|,|\Y|\}.
		\end{align}
		By assumption, \(\eta(\mA) < \log_2 \min \{|\X|,|\Y|\}\) holds true. Thus, we have \(\W_0\in \S_\star(\mA)\).
		For all \((x,y)\in\X\times \Y\), define
		\begin{align}
			W_1(y|x) := \frac{1}{|\Y|}.
		\end{align}
		Then, we have \(\Omega(W_1) = \X\times \Y\), and thus \(C_\star(W_1) = 0\). Hence, \(W_1 \in \U_\star(\mA)\cap \Wc(\X,\Y)\)
		is satisfied. Now define
		\begin{align}
			W(\mu) := (1-\mu)W_0 + \mu W_1.
		\end{align}
		For all \(\mu \in (0,1]\cap\RRc\), we have \(\Omega(W(\mu)) = \X\times\Y\) and thus \(C_\star(W(\mu)) = 0\).
		Hence, \(W(\mu) \in \U_\star(\mA)\cap\Wc(\X,\Y)\) is satisfied for all \(\mu \in (0,1]\cap\RRc\).
	\end{proof}
	
	\begin{Theorem}
		For \(\star \in \{\text{'\(0\)'},\text{'Fb'}\}\), (nonempty) finite alphabets \(\X\) and \(\Y\) and
		\(\mA\in\RRcP{n\times n}\) with \(\log_2\min\{|\X|,|\Y|\} > \eta(\mA) > 0\), the indicator function \(\mathds{1}_{\S_\star(\mA) \cap \Wc(\X,\Y)}\)
		is not Banach-Mazur computable.
	\end{Theorem}\begin{proof}
		The claim is a direct consequence of Lemmata \ref{lem:IndicatorFunctionBanachMazur} and \ref{lem:SstarSatisfiesProp} and
		the observation that \((\S_\star(\mA) \cup \U_\star(\mA)) \cap \Wc(\X,\Y)\) is a nonempty subset of \(\Wc(\X,\Y)\).
	\end{proof}
	
	\begin{Theorem}
		For \(\star \in \{\text{'\(0\)'},\text{'Fb'}\}\), (nonempty) finite alphabets \(\X\) and \(\Y\) and
		\(\mA\in\RRcP{n\times n}\) with \(\log_2\min\{|\X|,|\Y|\} > \eta(\mA) > 0\), the set \(\S_\star(\mA) \cap \Wc(\X,\Y)\)
		is not semi-decidable as a subset of \(\Wc(\X,\Y)\).
	\end{Theorem}\begin{proof}
		The claim is a direct consequence of Lemmata \ref{lem:SubsetNotSemidecidable} and \ref{lem:SstarSatisfiesProp} and
		the observation that \((\S_\star(\mA) \cup \U_\star(\mA)) \cap \Wc(\X,\Y)\) is a nonempty subset of \(\Wc(\X,\Y)\).
	\end{proof}
	
	\begin{Theorem}	\label{thm:RemoteStateEstimationBSSDecidable}
					Let \(\X,\Y\) be finite alphabets and \(\mA \in \RR^{n\times n}\) a characterization of an unstable, time-invariant, 
					linear plant. Then, the following holds true:
					\begin{itemize}	\item There exists a BSS machine \(\BSS_{\S}^{\mA}\) that \emph{decides} the set
										\(\S_{\mA}(\X,\Y)\) as a subset of \(\W(\X,\Y)\). That is, we have
										\begin{align*}	\BSS_{\S}^{\mA}(W) = 	\mathds{1}_{\S_{\mA}(\X,\Y)}(W)
										\end{align*}
										for all \(\W(\X,\Y)\).
									\item There exists a BSS machine \(\BSS_{\U}^{\mA}\) that \emph{decides} the set
										\(\U_{\mA}(\X,\Y)\) as a subset of \(\W(\X,\Y)\). That is, we have
										\begin{align*}	\BSS_{\U}^{\mA}(W) = 	\mathds{1}_{\U_{\mA}(\X,\Y)}(W)
										\end{align*}
										for all \(\W(\X,\Y)\).
					\end{itemize}
	\end{Theorem}\begin{proof}
					Consider again an enumeration \(j \mapsto \big(x(j), y(j)\big)\) of the set \(\X\times\Y\) 
					Define \(M_\mathrm{C} := 1\), \(M_\mathrm{B} := 2\) and \(M_\BSS := 4\) as well as \(J_\mathrm{R} = \max\{|\X\times \Y|,3\}\) and 
					\(J_\mathrm{C} = J_\mathrm{R} + 1\). Furthermore, hard-code the sole constant \(c_{J_\mathrm{C}}\) according to
					\(c_{J_\mathrm{C} } := \eta(\mA)\) and specify the program \(\G = ([M_\BSS],\V_\BSS)\) in the following way:
					\begin{enumerate}	\item[\(\iota\)\hspace{1pt}:] Preallocate the machine's registers \(\bm{r}\) according to
											\begin{align}	r^1_j :=	\begin{cases}	W\big(y(j)|x(j)\big)	&\text{if}~ j\leq |\X\times\Y|,\\
																						0						&\text{otherwise}
																		\end{cases}
											\end{align}
											and set \(\iota' := 1\).
										\item[\(\zeta\)\hspace{1pt}:] For \(\zeta \in \{1,\ldots, M_\mathrm{C}\} = \{1\}\) and \(e_t = e_1 = \zeta\), set \(\zeta' = 2\) and define 
											\(\bm{r}^{t+1} = \bm{r}^{2} := g_1(\bm{c},\bm{r}^1).
											\)
										\item[\(\beta\)\hspace{1pt}:] 
											For \(\beta \in \{M_\mathrm{C} + 1,\ldots, M_\mathrm{B}\} = \{2\}\), the pair of next nodes \(\big(\beta'(\mathsf{T}),
											\beta'(\mathsf{F})\big)\) satisfies
											\(\beta'(\mathsf{T}) :    =  3\) and \(\beta'(\mathsf{F}) :    =  4\).
											If \(e_t = e_2 = \beta\), then \(e_{t+1} = e_T = e_3\) satisfies
											\begin{align*}   e_{3} := 	\begin{cases}   \beta'(\mathsf{T}) &\text{if}~ 0 < r_1^3,\\
																						\beta'(\mathsf{F}) &\text{otherwise}.
																		\end{cases}
											\end{align*}
										\item[\(\sigma\)\hspace{1pt}:] We have \(\sigma \in \{3,4\}\). For \(\sigma = 3\), return \(r_2^3\). For \(\sigma = 4\), return \(r_3^3\).
					\end{enumerate}
					Last but not least, consider the mappings
					\begin{align*}	g_1^\S(\bm{r}^t,\bm{c}) :&= \big(\BSS_{C_0}(\bm{r}^t) - c_{J_\mathrm{C}}, 1, 0, \ldots, 0\big), \\
									g_1^\U(\bm{r}^t,\bm{c}) :&= \big(c_{J_\mathrm{C}} - \BSS_{C_0}(\bm{r}^t), 1, 0, \ldots, 0\big), 
					\end{align*}
					where \(\BSS_{C_0}\) denotes the BSS-computable mapping that computes the zero-error capacity according to Theorem \ref{thm:ZeroErrorBSScomputable}. 
					Setting \(g_1 := g_1^\S\) yields a triple \((\bm{r}, \bm{c}, \G)\)
					that characterizes \(\BSS_{\S}^{\mA}\). Likewise, setting \(g_1 := g_1^\U\) yields a triple \((\bm{r}, \bm{c}, \G)\)
					that characterizes \(\BSS_{\S}^{\mA}\).
	\end{proof}
	
	The algorithm specified in the proof of Theorem \ref{thm:RemoteStateEstimationBSSDecidable} does not depend on \(\mA\) in a BSS-computable manner,
	since the number \(\eta(\mA)\) has to be hard-coded into the algorithm. In practical applications however, the characteristics of the plant
	are usually known during the design process, whereas only the channel is likely to vary during the operation
	of the system. Hence, the fact that for each system, an individual algorithm has to be designed, is not necessarily a drawback in this context.
	
\section{Summary and Conclusion}	\label{sec:Conclusion}
	We have proven that for fixed alphabets \(\X,\Y\), the zero-error capacity \(C_0(W)\) is BSS-computable as a function on \(\W(\X,\Y)\).
	Furthermore, we have shown that for each \(\mA\in \RR^{n\times n}\) describing an unstable plant, the solvability of the remote state estimation
	problem is decidable on a BSS machines as a function on on \(\W(\X,\Y)\). Both results rely essentially on the ability of BSS machines to handle exact real numbers.
	
	The problem of remote state estimation via noisy channels is an explicit example of control and communications co-design. The criterion imposed on the control performance
	essentially determines the required communication performance. In \cite{MS07,BoBoDe21TAC}\tbr{{\color{red}\(\leftarrow\) Change to TAC!~}}, it was shown that the strong objective of almost sure observability requires the DMC to provide a sufficiently high
	zero-error capacity and is not semi-decidable on Turing machines. Furthermore, it was shown that the weakened control objective only requires the DMC to provide a sufficiently high
	Shannon capacity and is semi-decidable on a Turing machine. Here, we have shown that the strong objective is decidable on a Blum-Shub-Smale machine, which is generally more powerful than
	Turing machines. Hence, the objective of almost sure observability not only requires a stronger communication performance, but also a stronger computation model.
	
	The strong objective of almost sure observability is required for several real-world control engineering scenarios, especially those which potentially affect human safety or heal, e.g.
	autonomous driving. This highlights the importance of the precise understanding of the underlying mathematical theories of the models involved in the design process of these systems.

		
%\section*{Acknowledgment}

\bibliographystyle{ieeetran}
\bibliography{ZeroErrorBSS}

\end{document}
